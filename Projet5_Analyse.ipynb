{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet 5 - Catégorisez automatiquement des questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des librairies et des données et conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import scipy\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import csv\n",
    "from sklearn import preprocessing\n",
    "from sklearn import decomposition\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_validate\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix, plot_confusion_matrix\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mx = pd.read_csv('test_mx.csv', sep=';', index_col=0)\n",
    "train_mx = pd.read_csv('train_mx.csv', sep=';', index_col=0)\n",
    "fw_dict = pd.read_csv('fw_dict.csv')\n",
    "test_df = pd.read_csv('filtered_test_df.csv', sep=';',\n",
    "                      index_col=0, converters={'processed_tags': eval})\n",
    "train_df = pd.read_csv('filtered_df.csv', sep=';',\n",
    "                       index_col=0, converters={'processed_tags': eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = []\n",
    "with open('feature_name.csv', 'r') as data:\n",
    "    for line in csv.reader(data):\n",
    "        feature_name.append(line)\n",
    "\n",
    "# Transforme la liste de listes en liste\n",
    "feature_names = [item for sublist in feature_name for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw_dict = fw_dict.to_dict(orient='list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = scipy.sparse.csr_matrix(train_mx.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<34802x997 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1060544 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(learning_method='online', learning_offset=50.0,\n",
       "                          max_iter=5, n_components=11, random_state=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=11, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "\n",
    "lda.fit(train_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in LDA model: \n",
      "Topic #0:\n",
      "use javascript using would page like code way file j know html browser c jquery function window application one google need example time want image work question good java find script web chrome event used user library get net looking\n",
      "Topic #1:\n",
      "public thread class method exception static void task java catch private new system difference async throw test interface null println try return string block queue object code main call e final instance wait console boolean writeline args run override int\n",
      "Topic #2:\n",
      "java android org jar eclipse com gradle maven spring annotation dependency hibernate lang junit xml bean compile build support google plugin apache sun class project util internal springframework version activitythread servlet jdk test http main error source property v groupid\n",
      "Topic #3:\n",
      "android view layout button image activity app self color intent item text id io screen height swift fragment want width parent r background set change textview action bar programmatically new dialog animation notification show drawable size application keyboard like menu\n",
      "Topic #4:\n",
      "date input datetime form jquery button value text event click day function option time td javascript div label element format select month type id field html get mm submit name checkbox want var hour using alert child box year tr\n",
      "Topic #5:\n",
      "file python error project version app run install studio android c path application build window directory module package py using command library get xcode code running test lib installed use line ruby system visual folder import debug php program process\n",
      "Topic #6:\n",
      "c int class std function x foo type b return variable value const operator code char use object string public pointer f method compiler argument double void like bar error vector struct parameter member include template would using constructor static\n",
      "Topic #7:\n",
      "string array list value object python key number way convert like character item x c return want get function var b would name new print int n dictionary element java loop integer using line method map use one example data\n",
      "Topic #8:\n",
      "git branch commit repository file master repo remote github push merge change pull origin directory local command folder head want project delete status way one feature tag fatal team ref like add fetch reset get working back new using would\n",
      "Topic #9:\n",
      "table div column row sql id cs query mysql px select width cell li height text image database style class like font color value data html element name panda want using span df background border insert dataframe left top index\n",
      "Topic #10:\n",
      "request user url data model json http error get name post response server string id new using file php function return password email public com controller app session net set client code var react connection log api rail username page\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 40\n",
    "print(\"\\nTopics in LDA model: \")\n",
    "print_top_words(lda, feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On extrait le 1er tag de chaque ligne pour créer 'y' de la base train et test. Il faut encoder les données sur le dataframe contenant toutes les données pour éviter des problèmes liés avec des tags qui apparaissent dans une base et non l'autre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = pd.concat([train_df, test_df])\n",
    "pre_base = [full_df['processed_tags'].iloc[i][0]\n",
    "            for i in range(len(full_df['processed_tags']))]\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(pre_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_ytrain = [train_df['processed_tags'].iloc[i][0]\n",
    "              for i in range(len(train_df['processed_tags']))]\n",
    "y_train = le.transform(pre_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_ytest = [test_df['processed_tags'].iloc[i][0]\n",
    "             for i in range(len(test_df['processed_tags']))]\n",
    "y_test = le.transform(pre_ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation de la base train\n",
    "std_scale = preprocessing.StandardScaler().fit(train_mx)\n",
    "X_scaled = std_scale.transform(train_mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation de la base test selon la base test\n",
    "X_scaled_test = std_scale.transform(test_mx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On test l'ACP avec plusieurs nombres de composants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On calcul les 2 premieres composantes principales\n",
    "pca = decomposition.PCA(n_components=800).fit(X_scaled)\n",
    "\n",
    "# projeter X sur les composantes principales\n",
    "train_projected = pca.transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_projected = pca.transform(X_scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8696, 800)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_projected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.881514688185973\n"
     ]
    }
   ],
   "source": [
    "# Pourcentage de la variance expliquee\n",
    "# print(pca.explained_variance_ratio_)\n",
    "print(pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAHwCAYAAADuJ7gwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdd5SV1dmG8esRu7GLMbHHqIkaK1E09hI7YI0NRbFFid3YYiPW2BELVhAbURNBJCpGbIhKEU3sRFFAjT2gIG3298c+5BsJzBxgzrwzZ67fWrM4bc7cM2ctc2fv/e4dKSUkSZLUuOYrOoAkSVJLZAmTJEkqgCVMkiSpAJYwSZKkAljCJEmSCmAJkyRJKoAlTKpiEdEpIp6v0HuPjogdS7fPjojbGuA9e0bERfOermFERIqInxadQ1J1mr/oAJLmTUSMBn4ITK/1cM+UUpfGypBSuqSxfpYkVQtLmFQd9kwpPVl0CJUnIlqllKbX/8o5ft8AIqVU00DvN39KaVpDvJek/+V0pFT9IiKuj4j/RMRbEbFDrSd+HBH9IuLLiBgVEUfVeu57U4MRsW1EjJ3ND7ggIu4u3V44Iu6OiC8i4uuIGBoRP5zN920UESMiYkJE9AEWnun5PSJiZOl9XoiI9Ws9d0ZEjCt979u1f69ar2kbEZ9ERKtaj+0VEa+Vbm8aEUNK7/9xRHSPiAVnk3WhiLgyIj6MiH9HxM0RsUjpuf+Z9q09lVn6W94UEQMi4ltgu4jYLSLeKOUfFxGnzebndoqIwXV8hk9HxMURMRiYCPykns/1goh4MCL6lH72iIjYoNbzo0t/29eAbyNi/tL7PRQRn0XE+xFxQq3XbxoRwyJifOnvcvWsfg9J/8sSJlW/zYD3gOWA84G/RMQypefuA8YCPwb2BS6ZVZmZQ4cBSwIrA8sCxwKTZn5Rqew8DPQGlgEeAPap9fzGwB3AMaX36QH0K5WhtYEuwC9TSosDOwOjZ/4ZKaUXgW+B7Ws9fBBwb+n2dOBk8t9mc2AH4LjZ/F6XA2sBGwI/BVYEzqvrDzGTg4CLgcWB54HbgWNK+dcDnqrje+v6DAE6AkeX3vsD6v9c25P/3suQ/xYPR8QCtZ4/ENgdWAqoAR4BXi39zjsAJ0XEzqXXXgdcl1JaAlgD+HOZfw+pxbOESdXh4dJozoyvo2o99ylwbUppakqpD/A2sHtErAxsCZyRUvoupTQSuI38P+jzYiq5NP00pTQ9pTQ8pTR+Fq9rCyxQK9uDwNBazx8F9EgpvVR6n17A5NL3TQcWAtaJiAVSSqNTSv+aTZ77yKWCiFgc2K30GKVsL6aUpqWURpOL3jYzv0Fpmu8o4OSU0pcppQnAJcABc/B36ZtSGpxSqkkpfVf6O60TEUuklL5KKY2o43tn+RnWer5nSun10tThCtT/uQ5PKT2YUpoKXE0egWxb6/luKaUxKaVJwC+B1imlrimlKSml94Bba/3uU4GfRsRyKaVvSsVXUhksYVJ16JBSWqrW1621nhuXUkq17n9AHiH5MTCjUNR+bsV5zNIbeBy4PyI+iog/zTTKMsOPZ5NthlWBU2uXS/Lo2o9TSqOAk4ALgE8j4v6I+PFs8twL7B0RCwF7AyNSSh8ARMRaEdG/NGU5nlyslpvFe7QGFgWG18ryWOnxco2Z6f4+5EL4QUQ8ExGb1/G9s/sMZ/Xe5Xyu/319af3YjFGzWb3fqsCPZ/ocziZfDALQmTxC+FZp6nmPOn4PSbVYwqTqt2JpJGeGVYCPSl/LlEaHaj83rnT7W3LxmGGFcn5YabTmwpTSOsAWwB7AobN46cezyTbDGODimcrloimlGaNY96aUtiSXhESeLpxVnjfIJWRXvj8VCXAT8BawZmk67Wwg/udN4HPylOq6tbIsmVL6Qen57/2tImJWf6v0vTspDU0ptQeWJ0/L1jWNN7vPcFbvXd/nCrnMzsg6H7BSHe83Bnh/ps9h8ZTSbqXf492U0oGl3+Ny4MGIWKyO30VSiSVMqn7LAydExAIRsR/wc2BASmkM8AJwaeTF9OuTRzXuKX3fSGC3iFimVCpOKueHRcR2EfGL0mL48eTpqlldCTgEmFbKNn9E7A1sWuv5W4FjI2KzyBaLiN0jYvGIWDsiti+Nbn1HLkh1XW14L3ACsDV5LdQMi5cyfhMRPwN+O6tvLo0W3QpcExHLl37PFWuti3oVWDciNoyIhckjdLMVEQtGxMERsWRpSnB8Pfln+RnOJmt9nyvAJhGxd0TMT/5cJwOzm0Z8GRhfWqy/SES0ioj1IuKXpd/lkIhoXfobfV36nga/8lOqRpYwqTo8EhHf1Pr6a63nXgLWJI/mXAzsm1L6ovTcgcBq5FGQvwLnp5QGlp7rTS4Xo4EngD5lZlkBeJBcLN4EngHunvlFKaUp5OnBTsBXwG+Av9R6fhh5HVb30vOjSq+FvB7sstLv9Am5pJxdR6b7gG2Bp1JKn9d6/DTy6NgEcsmq63c8o5ThxdLU5ZPA2qWs7wBdS4+9S154X5+OwOjSex0LHFLHa+v6DGelrs8VoC/57/1VKcfepTL4P0pbaexJviDh/VKG28gXXwDsArweEd+QF+kfUFrzJqke8f1lBpKkpiQiOgFHlqZeG+L9LiBfNFFX6ZPUCBwJkyRJKoAlTJIkqQBOR0qSJBXAkTBJkqQCWMIkSZIKMH/RAebUcsstl1ZbbbWiY0iSJNVr+PDhn6eUZnm6RrMrYautthrDhg0rOoYkSVK9IuKD2T3ndKQkSVIBLGGSJEkFsIRJkiQVwBImSZJUAEuYJElSASxhkiRJBbCESZIkFcASJkmSVABLmCRJUgEsYZIkSQWwhEmSJBXAEiZJklQAS5gkSVIBLGGSJEkFsIRJkiQVwBImSZJUAEuYJElqeT75BCZOLDSCJUySJLUcX3wBZ5wBP/kJ3HBDoVHmL/SnS5IkNYavv4Zrrslf33wDBx0EHToUGskSJkmSqtc338D118MVV8BXX8G++8IFF8C66xadzBImSZKq0HffQY8ecPHF8NlnsMce0LUrbLRR0cn+yzVhkiSpekybBnfcAWutBSedBOutB0OGwCOPNKkCBpYwSZJUDWpq4IEHcunq3BlWWAEGDoSnnoK2bYtON0uWMEmS1HylBI89Bm3awP77Q6tW8Ne/wksvwY47Fp2uTpYwSZLUPA0eDNtsA7vumhfd33UXvPZavuoxouh09bKESZKk5mXkSNh9d9hyS3j33bzf19tvQ8eOeSSsmbCESZKk5uGdd+CAA/IC+yFD4LLLYNQoOO44WHDBotPNMbeokCRJTduYMXl7iTvvhIUWgnPOgdNOg6WWKjrZPLGESZKkpunzz+GSS+DGG/MC/OOPh7PPhh/+sOhkDcISJkmSmpZvv4Vrr4U//SnveH/YYXD++bDqqkUna1CWMEmS1DTM2Gj1ggvg44+hffs8ErbOOkUnqwhLmCRJKlZKeW+vs87Ki++32CJvvPqrXxWdrKK8OlKSJBXn2Wdh881hn33y9hJ9+8Lzz1d9AQNLmCRJKsI//pEP1d5mGxg7Fm6/PW+02q5ds9hotSFYwiRJUuP58EM4/HDYYIM84nXZZXkK8ogjYP6WtUqqZf22kiSpGF9+CZdeCtdfn++fempeA7bMMsXmKpAlTJIkVc6kSdCtWy5g48fn7SYuvBBWWaXoZIVzOlKSJDW86dPzdhNrrglnnpnPeXz11bzrvQUMsIRJkqSGlBL87W+w4YbQuTOstBI8/TT07w+/+EXR6ZoUS5gkSWoYr74Kv/417LZbnoZ84IF80PY22xSdrEmyhEmSpHkzbly+unGjjWDEiHzk0BtvwL77tpjtJuaGC/MlSdLcmTAhn+941VV5Ddipp+YDtpdeuuhkzYIlTJIkzZlp0/LmquedB59+CgceCBdfDKuvXnSyZsUSJkmSypMSDBgAp58Ob76Zr3h85BHYdNOikzVLrgmTJEn1e+UV2HHHfNTQtGn5wO1nn7WAzQNLmCRJmr0xY/IGq5tskq9+vP56eP116NDBRffzyOlISZL0v8aPh8svh6uvztOQv/993nR1qaWKTlY1LGGSJOn/TZ0Kt90G558Pn30GBx+cF92vumrRyaqOJUySJOXRrkcfzYvu33oLtt46L8Jv06boZFXLNWGSJLV0//wn7Lwz7Lkn1NRA3775qCELWEVZwiRJaqk++wx++1vYYAMYNizvdP/Pf0K7di66bwQVLWERsUtEvB0RoyLizFk8v0pEDIqIVyLitYjYrZJ5JEkSMHkyXHkl/PSncOutcPzx8O67cOKJsMACRadrMSpWwiKiFXADsCuwDnBgRKwz08v+APw5pbQRcABwY6XySJLU4qUEDz8M666b135tuSX84x/QrRssu2zR6VqcSo6EbQqMSim9l1KaAtwPtJ/pNQlYonR7SeCjCuaRJKnlGjkStt8e9toLFloIHnssL8T/+c+LTtZiVbKErQiMqXV/bOmx2i4ADomIscAA4HezeqOIODoihkXEsM8++6wSWSVJqk6ffAJHHgkbb5xHvW64IW+6uvPORSdr8SpZwma1oi/NdP9AoGdKaSVgN6B3RPxPppTSLSmlNimlNq1bt65AVEmSqsx338Gll8Kaa0KvXnDyyXnd13HHwfzuUNUUVPJTGAusXOv+SvzvdGNnYBeAlNKQiFgYWA74tIK5JEmqXinBgw/mHe5Hj85XOl5xBay1VtHJNJNKjoQNBdaMiNUjYkHywvt+M73mQ2AHgIj4ObAw4HyjJElzY9iwvMnq/vvD4ovDk0/mPb8sYE1SxUpYSmka0AV4HHiTfBXk6xHRNSLalV52KnBURLwK3Ad0SinNPGUpSZLq8vHHcPjh8MtfwttvQ48e8MorsMMORSdTHSo6KZxSGkBecF/7sfNq3X4D+FUlM0iSVLWmTIHrroOuXfPeX6efDuecA0suWXQylcGVeZIkNUePPvr/i+332AOuvjovwlez4bFFkiQ1J2+/DbvtlovXfPPB3/4GjzxiAWuGLGGSJDUH//kPnHYarLceDB4MV10Fr70Gu+xSdDLNJacjJUlqympqoGdPOOusfOD2EUfAxRfDD39YdDLNI0uYJElN1ZAhcMIJeeuJzTfP68DatCk6lRqI05GSJDU1H30EHTvCFlvk23ffnacgLWBVxRImSVJTMXkyXHZZ3lz1z3/OU5Bvvw0HHwwxq9MA1Zw5HSlJUtFSylc4nnIK/Otf0L59Xni/xhpFJ1MFORImSVKR3norX+HYvj0suCA88QQ8/LAFrAWwhEmSVIQJE/Ih27/4Bbz0Elx7Lbz6Kuy0U9HJ1EicjpQkqTGlBPffn/f8+uijvOXEpZfC8ssXnUyNzJEwSZIayz//CdtvDwcdBCuskLeguP12C1gLZQmTJKnS/vOffM7jhhvmXe5vvhlefhnati06mQrkdKQkSZWSEvTundd+ffopHH103u1+2WWLTqYmwBImSVIljBwJXbrkTVY32wz693ezVX2P05GSJDWkr77K5WuTTfJGq7ffDi+8YAHT/3AkTJKkhlBTA3feCWeeCV9+CccdB127wtJLF51MTZQjYZIkzasZB2wfeSSsvTYMHw7XX28BU50sYZIkza3PP4djjoFNN4UPPoC77oLnnstXQUr1sIRJkjSnpk+HHj3yqNftt8NJJ+X1Xx07etC2yuaaMEmS5sSIEfDb3+Z9vrbZBrp3h/XWKzqVmiFHwiRJKsfXX8Pvfge//GWeerz7bhg0yAKmueZImCRJdUkJ7r0XTj0VPvssX/X4xz/CUksVnUzNnCVMkqTZeeutXLoGDcojYI8+mvf/khqA05GSJM1s4kQ45xxYf3145RW46aZ82LYFTA3IkTBJkmp75JG89uuDD+Cww+BPf4Llly86laqQI2GSJAGMHg3t20O7drDYYvDMM9CzpwVMFWMJkyS1bFOmwGWXwTrrwJNP5pGvkSNh662LTqYq53SkJKnlGjQoL7x/6y3Yay+49lpYZZWiU6mFcCRMktTyfPIJHHIIbL89TJ4M/fvDX/5iAVOjsoRJklqO6dPhhhvgZz+DBx6Ac8+F11+H3XcvOplaIKcjJUktw/Dh+bDt4cNhhx1yGVt77aJTqQVzJEySVN0mTMgHbG+6KYwdC/fdBwMHWsBUOEfCJEnV6+GH855f48bBscfCJZd43JCaDEfCJEnV58MP855fe+0FyywDL7wAN95oAVOTYgmTJFWPadPg6qu/v+fXsGHQtm3RyaT/4XSkJKk6DB0KRx+dN1rdbbe88H611YpOJc2WI2GSpOZt/Pi87muzzeDf/85bT/TvbwFTk+dImCSpeUopb7B6wgnw8cdw/PFw0UWw5JJFJ5PK4kiYJKn5GT0a9twT9t03H7D94otw/fUWMDUrljBJUvMxdSpceSWsuy48/TRcdVVeC7bppkUnk+aY05GSpObhpZfyjvevvppHwbp396xHNWuOhEmSmrbx46FLF9h8c/j887wOrG9fC5iaPUfCJElNV9++ecH9Rx/lKyAvuggWX7zoVFKDcCRMktT0fPxxXnTfoUPe8X7IELjuOguYqoolTJLUdNTUwC23wM9/nvf6uvhiGD487wEmVRmnIyVJTcPbb+cd7599FrbdFnr0gLXWKjqVVDGOhEmSijVlSl7rtcEG8NprcNtt8NRTFjBVPUfCJEnFefFFOOoo+Oc/Yf/987qvFVYoOpXUKBwJkyQ1vgkT8tWOW2wBX38NjzwCffpYwNSiWMIkSY3rkUdgnXXghhvy/l9vvAF77FF0KqnRWcIkSY3jk0/ylGO7dvmMxxdegG7d3HZCLZYlTJJUWSnlxfY//3nefPWPf4QRI6Bt26KTSYVyYb4kqXLeeSdvO/HMM7D11nkPsLXXLjqV1CQ4EiZJanjTpsHll8P668PIkbl8DRpkAZNqcSRMktSwXn0VjjgiTznuvTd07w4/+lHRqaQmx5EwSVLDmDwZ/vAHaNMGxo2DBx+Ehx6ygEmz4UiYJGneDRkCnTvDm2/CoYfCNdfkg7clzZYjYZKkufftt3DSSfCrX+Xbf/sb9OplAZPK4EiYJGnuPPlkPnJo9Gg4/ni49FL3/JLmgCNhkqQ58/XXeepxp51ggQXg2Wfz4nsLmDRHLGGSpPL17ZuPHOrVC844I18JudVWRaeSmqV6S1hkh0TEeaX7q0TEppWPJklqMj79FH7zG+jQAZZfHl56CS67DBZZpOhkUrNVzkjYjcDmwIGl+xOAGyqWSJLUdKQE99yTR78efjgfOTR0KGyySdHJpGavnIX5m6WUNo6IVwBSSl9FxIIVziVJKtqYMfDb38Kjj+ZzHm+/PZcxSQ2inJGwqRHRCkgAEdEaqKloKklScWpq4OabYd1181FD114Lzz9vAZMaWDkjYd2AvwI/jIiLgX2BP1Q0lSSpGP/6Fxx5JDz9NOywQz7z8Sc/KTqVVJXqLWEppXsiYjiwAxBAh5TSmxVPJklqPDU1eZuJs86C+eeHW2/N21BEFJ1Mqlrlbta6HDAxpXRnRLSOiNVTSu9XMpgkqZGMGpUP3H7uOdh11zz6tdJKRaeSql45W1ScD5wBnFV6aAHg7kqGkiQ1gpoauO46WH99eO01uPPOvAjfAiY1inJGwvYCNgJGAKSUPooIt0WWpObs3Xfz6Nfzz8Nuu+XRrxVXLDqV1KKUc3XklJRS4v+vjlysspEkSRUzfXq+2nGDDeAf/4CePaF/fwuYVIByRsL+HBE9gKUi4ijgCODWysaSJDW4d97Jo1+DB8Mee+RtKCxfUmHKuTryyojYCRgPrA2cl1IaWPFkkqSGMX16Xvt1zjmw8MJw111wyCFe+SgVrKyrI0uly+IlSc3N22/D4YfDkCGw557Qowf86EdFp5JEeVdHToiI8aWv7yJiekSMb4xwkqS5NH06XHklbLghvPUW3H039O1rAZOakHKmI793JWREdAA2rVgiSdK8eeutPPr14ovQrl1e+2X5kpqccq6O/J6U0sPA9hXIIkmaF9OnwxVX5NGvd96Be+6Bhx+2gElNVL0jYRGxd6278wFtKG1XIUlqIt56Czp1gpdegg4d4KabYIUVik4lqQ7lLMzfs9btacBooH1F0kiS5syMXe/PPhsWXRTuvRcOOMArH6VmoJw1YYc3RhBJ0hx677289uvZZ/OVj7fc4uiX1IyUMx3Zra7nU0on1PG9uwDXAa2A21JKl83iNfsDF5CnOF9NKR1UXyZJatFSyltNnHYatGqVd70/9FBHv6RmppzpyIWBdYA+pfv7AcOBkXV9U0S0Am4AdgLGAkMjol9K6Y1ar1mTfDD4r1JKX0XE8nP+K0hSCzJ2LHTuDE88ATvuCHfcASuvXHQqSXOhnBK2JrBdSmkqQETcDDyRUjq5nu/bFBiVUnqv9H33k9eSvVHrNUcBN6SUvgJIKX06h/klqWVICXr3hhNOgKlT4cYb4dhjHf2SmrFytqj4MVB7r7AflB6rz4rAmFr3x5Yeq20tYK2IGBwRL5amLyVJtf3737DXXnDYYfCLX8Brr8Fvf2sBk5q5ckbCLgNeiYhBpfvbkNdw1WdW/3WYeWuL+ckjbdsCKwHPRcR6KaWvv/dGEUcDRwOsssoqZfxoSaoSDz6YR7y++SbvgH/SSXkdmKRmr96RsJTSncBmwF9LX5unlHqV8d5jgdoLFVYCPprFa/qmlKamlN4H3iaXspkz3JJSapNSatO6desyfrQkNXNffgkHHQT77Qerrw4jRsCpp1rApCoy2xIWET8r/bsxefpxTOnrx6XH6jMUWDMiVo+IBYEDgH4zveZhYLvSz1mOPD353pz+EpJUVR59FNZbDx54ALp2hRdegHXWKTqVpAZW13TkqeSF81fN4rlEPUcXpZSmRUQX4HHyFhV3pJRej4iuwLCUUr/Sc7+OiDeA6cDpKaUv5uL3kKTmb/x4OOUUuP32vPbr0Udho42KTiWpQiKl5nUCUZs2bdKwYcOKjiFJDeupp/LGq2PHwhlnwPnnw0ILFZ1K0jyKiOEppTazem62I2EznRn5P1JKf5nXYJLU4k2cCGeeCddfD2utBYMHQ9u2RaeS1Ajqmo7cs47nEmAJk6R58dJL0LEjvPsunHgiXHJJPv9RUosw2xLmmZGSVCFTp8JFF8HFF8OKK+apyO22KzqVpEZWztmRywLnA1uSR8CeB7q6gF6S5sJbb+XRr2HD8nmP3brBkksWnUpSAcrZMf9+4DNgH2Df0u0+dX6HJOn7amqge/d8teP77+dNWHv1soBJLVg5O+Yvk1L6Y637F0VEh0oFkqSqM25cvvJx4EDYdde8BcWPflR0KkkFK2ckbFBEHBAR85W+9gcerXQwSaoKffrkPb8GD4abbsp7f1nAJFFeCTsGuBeYXPq6HzglIiZExPhKhpOkZuurr/KxQwcckLeeGDkynwHpoduSSuqdjkwpLd4YQSSpajz5JHTqBP/+dz526KyzYP5yVn9IaknqHQmLiM4z3W8VEedXLpIkNVOTJuX9vnbaCRZfHIYMgXPPtYBJmqVypiN3iIgBEfGjiPgF8CLg6Jgk1TZ8OGy8cd5y4oQTYMQIaDPLk0okCShvOvKgiPgN8A9gInBgSmlwxZNJUnMwbRpcdhlceCH88IfwxBN5JEyS6lHOdOSawInAQ8BooGNEeK6GJL37Lmy1VZ5y3G8/+Mc/LGCSylbOdOQjwHkppWOAbYB3gaEVTSVJTVlK0KMHbLhh3gH/vvvg3nth6aWLTiapGSlnteimKaXxACmlBFwVEf0qG0uSmqhPP4Ujjsj7fe24I9x5J6y0UtGpJDVD5YyETYuIcyPiVvjv9OTalY0lSU3QgAF549Unn4Rrr4XHH7eASZpr5ZSwO8mbtG5euj8WuKhiiSSpqZk0Cbp0gd13z4vvhw7NW1HMV85/QiVp1sr5L8gaKaU/AVMBUkqTALd8ltQyjBwJm2wCN9wAJ58ML7+cR8MkaR6VU8KmRMQiQAKIiDXII2OSVL1qauDKK2HTTeHrr/PU49VXw8ILF51MUpUoZ2H++cBjwMoRcQ/wK6BTJUNJUqHGjoXDDoOnnoK99oJbboHllis6laQqU85mrQMjYgTQljwNeWJK6fOKJ5OkIjz4IBx9NEyeDLfeCp07e+i2pIoo60CzlNIXwKMVziJJxZkwIR831LMn/PKXcM89sOaaRaeSVMW8tEeSXnwxb7x6111wzjkweLAFTFLFWcIktVzTpkHXrrDlljB9OjzzDFx0ESywQNHJJLUAZZWwiNgyIg4v3W4dEatXNpYkVdh778E228D558OBB8Krr+YyJkmNpJwDvM8HzgDOKj20AHB3JUNJUsWklKcdN9wQXn89n/nYuzcsuWTRySS1MOWMhO0FtAO+BUgpfQQsXslQklQRX3+dR70OOww22iiPfh14YNGpJLVQZW3WWjq4e8ZmrYtVNpIkVcDgwbDBBvDQQ3DJJXkPsFVXLTqVpBasnBL254joASwVEUcBTwK3VjaWJDWQadPgwgth661h/vlzGTvrLGjVquhkklq4cjZrvTIidgLGA2sD56WUBlY8mSTNqw8/hEMOgeeey//ecAMssUTRqSQJKKOEla6EfG5G8YqIRSJitZTS6EqHk6S59tBDcOSReSSsd+9cwiSpCSlnOvIBoKbW/emlxySp6Zk4MR87tO++sNZaMHKkBUxSk1ROCZs/pTRlxp3S7QUrF0mS5tKrr0KbNnDbbXDmmfD887DGGkWnkqRZKqeEfRYR7WbciYj2gAd4S2o6UoJu3WDTTfM2FAMHwqWXuvO9pCatnAO8jwXuiYjuQABjgEMrmkqSyvXZZ3D44fDoo7DHHnDHHdC6ddGpJKle5Vwd+S+gbUT8AIiU0oTKx5KkMgwcCIceCl99BddfD8cfDxFFp5KkspRzdeRCwD7AasD8UfoPXEqpa0WTSdLsTJkCf/gDXHEF/Pzn8PjjsP76RaeSpDlSznRkX+A/wHBgcmXjSFI9Ro3KRw0NGwbHHANXXw2LLlp0KkmaY+WUsJVSSrtUPIkk1ad3bzjuuLzg/qGHYO+9i04kSXOtnKsjX4iIX1Q8iSTNzoQJea+vQw+FjTfOW1FYwCQ1c+WMhFfAvTAAACAASURBVG0JdIqI98nTkQGklJILMCRV3ogR8JvfwHvvQdeucPbZnvsoqSqUU8J2rXgKSZpZStC9O5x2Wt5y4umnYautik4lSQ2mnC0qPgCIiOWBhSueSJK+/BI6d4aHH857f/XsCcsuW3QqSWpQ9a4Ji4h2EfEu8D7wDDAa+FuFc0lqqV54ATbaKG++es010K+fBUxSVSpnYf4fgbbAOyml1YEdgMEVTSWp5ampyUcNbb01zD9/LmMnneTmq5KqVjklbGpK6QtgvoiYL6U0CNiwwrkktST//jfssktedL/vvnkxfps2RaeSpIoqZ2H+16Uji54lnyH5KTCtsrEktRhPPpm3n/jPf+CWW+DIIx39ktQilDMS1h6YBJwMPAb8C9izkqEktQDTpuWjh379a1hmGXj5ZTjqKAuYpBajnKsjv611t1cFs0hqKcaMyUcPDR4MRxwB3brBYosVnUqSGtVsS1hEPJ9S2jIiJgCp9lPkzVqXqHg6SdWnXz/o1AmmToV77oGDDio6kSQVYrYlLKW0ZenfxRsvjqSqNXkynHEGXHdd3oKiTx9Yc82iU0lSYepcExYR80XEPxsrjKQqNWoUbLFFLmAnnABDhljAJLV4dZawlFIN8GpErNJIeSRVm/vvz4duv/8+/PWvuYgttFDRqSSpcOVsUfEj4PWIeBn47yL9lFK7iqWS1Px99x2cfDLcfHMeBbvvPljF/z8nSTOUU8IurHgKSdVl1CjYf3945RU4/XS4+GJYYIGiU0lSk1LOFhXPNEYQSVXioYfythOtWuUrIfd0W0FJmpVyDvBuGxFDI+KbiJgSEdMjYnxjhJPUjEyenBfd77sv/OxneRTMAiZJs1XOjvndgQOBd4FFgCNLj0lS9v77sNVWcP31+dDt556DVVctOpUkNWnlrAkjpTQqIlqllKYDd0bECxXOJam56Ns3b76aUp6K3HvvohNJUrNQTgmbGBELAiMj4k/Ax4Dni0gt3dSpcOaZcPXVeQuKBx6An/yk6FSS1GyUMx3ZsfS6LuQtKlYG9qlkKElN3JgxsM02uYAdd1w+A9ICJklzpJyRsI2BASml8bhdhaQBA6BjxzwSdv/98JvfFJ1IkpqlckbC2gHvRETviNg9IspaRyapykybBmedBbvvDiuvDMOHW8AkaR7UW8JSSocDPwUeAA4C/hURt1U6mKQmZNw42H57uOwyOPpoz36UpAZQ7tWRUyPib0Aib1PRnrxVhaRqN3AgHHwwTJwId9+db0uS5lk5m7XuEhE9gVHAvsBt5PMkJVWzmhq48ELYeWdYfnkYNswCJkkNqJyRsE7A/cAxKaXJlY0jqUn4/HM45BB4/HE49FC46SZYdNGiU0lSVSnn7MgDGiOIpCbi5Zdhv/3gk0+gRw846iiIKDqVJFWdcq6OlNQSpJRHvLbcMpeuwYPzInwLmCRVhCVMEnz7bZ52PO442HFHGDEC2rQpOpUkVTVLmNTSvf02bLYZ3HMP/PGP0L8/LLNM0akkqerVuyYsItYELgXWARae8XhKyTNKpObuwQfhiCNgoYXyIvyddio6kSS1GOWMhN0J3ARMA7YD7gJ6VzKUpAqbOhVOOSUvwF933Tz9aAGTpEZVTglbJKX0dyBSSh+klC4Atq9sLEkVM24cbLcdXHMN/O538Mwz+RgiSVKjKmefsO8iYj7g3YjoAowDlq9sLEkVMWgQHHBAXoh/3335tiSpEOWMhJ0ELAqcAGwCdAQOq2QoSQ2spiaf+7jjjrDssjB0qAVMkgpWzmatQ0s3vwEOr2wcSQ3uq6/gsMPgkUdy8br1VvjBD4pOJUkt3mxLWEQ8Qj6we5ZSSu0qkkhSw3nlFdhnHxg7Frp1gy5d3HxVkpqIukbCrmy0FJIaXs+e8NvfwnLLwbPPQtu2RSeSJNUy2xKWUnqmMYNIaiBTpsBJJ+UjiHbYIS/Ab9266FSSpJm4Y75UTcaNg222yQXsjDPgsccsYJLURFW0hEXELhHxdkSMiogz63jdvhGRIsLD6qS59cwzsPHG8M9/5p3wL7sM5i9nFxpJUhHKLmERsdicvHFEtAJuAHYlH3l0YESsM4vXLU7e/uKlOXl/SSUp5Y1Xd9gBll4aXn45L8aXJDVp9ZawiNgiIt4A3izd3yAibizjvTcFRqWU3kspTQHuB9rP4nV/BP4EfFd+bElA3nT1oIPyEUTt2uUC9vOfF51KklSGckbCrgF2Br4ASCm9CmxdxvetCIypdX9s6bH/ioiNgJVTSv3LSivp/40ala94/POf4dJL4aGHYIklik4lSSpTWQtGUkpj4vt7C00v49tmtRnRf/cdKx2FdA3Qqd43ijgaOBpglVVWKeNHS1Wuf3845BBo1SovvvfwbUlqdsoZCRsTEVsAKSIWjIjTKE1N1mMsUPtU4JWAj2rdXxxYD3g6IkYDbYF+s1qcn1K6JaXUJqXUprVXeqklq6mBCy6APfeENdaA4cMtYJLUTJVTwo4FjidPJY4FNizdr89QYM2IWD0iFgQOAPrNeDKl9J+U0nIppdVSSqsBLwLtUkrD5vB3kFqGr77K5evCC6FTJ3j+eVhttaJTSZLmUjlnR34OHDynb5xSmhYRXYDHgVbAHSml1yOiKzAspdSv7neQ9F+vvQZ77QVjxuQ9wI45xuOHJKmZq+vsyOup++zIE+p785TSAGDATI+dN5vXblvf+0kt0r33wpFH5u0nnnkGNt+86ESSpAZQ13TkMGA4sDCwMfBu6WtDyluYL2leTJ2ajx86+GD45S/z+i8LmCRVjbrOjuwFEBGdgO1SSlNL928GnmiUdFJL9dlnsN9+eeTrxBPhiitggQWKTiVJakDlbFHxY/KVjF+W7v+g9JikShgxIq//+vRT6N07b0UhSao65ZSwy4BXImJQ6f42wAUVSyS1ZPfck9d/tW6dr37cZJOiE0mSKqScqyPvjIi/AZuVHjozpfRJZWNJLcy0aXDmmXDVVbD11vDAA7D88kWnkiRVULk75n8C9K1wFqll+uILOOAAePJJOP74fBi3678kqeqVVcIkVchrr0GHDjBuHNx2G3TuXHQiSVIjKWfHfEmV8OCDecuJ777LV0FawCSpRSmrhEXElhFxeOl264hYvbKxpCo2fTqcc07egmKDDfL+X23bFp1KktTI6p2OjIjzgTbA2sCdwALA3cCvKhtNqkJff503Xx0wIF8F2b07LLRQ0akkSQUoZ03YXsBGwAiAlNJHEbF4RVNJ1ejNN6F9e3j/fc9/lCSVVcKmpJRSRCSAiFiswpmk6tO3L3TsCIssAk89BVttVXQiSVLBylkT9ueI6AEsFRFHAU8Ct1Y2llQlamrgwgvzFZBrrw3DhlnAJElAeZu1XhkROwHjyevCzkspDax4Mqm5mzABDj0UHn44/3vzzXkkTJIkyt+sdSBg8ZLK9f770K4dvPFG3nz1xBNd/yVJ+p5yro6cAKSZHv4PMAw4NaX0XiWCSc3WM8/APvvkrSgeewx22qnoRJKkJqickbCrgY+Ae4EADgBWAN4G7gC2rVQ4qdnp0QO6dIE11oB+/WCttYpOJElqospZmL9LSqlHSmlCSml8SukWYLeUUh9g6Qrnk5qHqVNz+Tr2WNhxR3jpJQuYJKlO5ZSwmojYPyLmK33tX+u5macppZbnyy9hl13ghhvg1FOhf39YcsmiU0mSmrhypiMPBq4DbiSXrheBQyJiEaBLBbNJTd8bb+QF+GPGwJ13QqdORSeSJDUT5WxR8R6w52yefr5h40jNyIABcMABsOiiMGgQbLFF0YkkSc1IOVdHLgx0BtYFFp7xeErpiArmkpqulODKK+GMM2DDDfNu+CuvXHQqSVIzU86asN7kqyF3Bp4BVgImVDKU1GR99x0cdhj8/vew777w3HMWMEnSXCmnhP00pXQu8G1KqRewO/CLysaSmqCPP4Ztt4XevaFrV+jTBxbzKFVJ0twpZ2H+1NK/X0fEesAnwGoVSyQ1RcOHQ/v28NVX8OCDeTNWSZLmQTkjYbdExNLAH4B+wBvA5RVNJTUlffrkQ7dbtYIXXrCASZIaRDkl7O8ppa9SSs+mlH6SUloeeKLSwaTCpQTnn5+vgNxkExg6FDbYoOhUkqQqUU4Je2gWjz3Y0EGkJmXSJDjwwLz2q1Mn+PvfYfnli04lSaois10TFhE/I29LsWRE7F3rqSWotVWFVHU++SSv/xo6FC6/HE4/HSKKTiVJqjJ1LcxfG9gDWIrvb9Y6ATiqkqGkwrz6Kuy5J3zxBfzlL9ChQ9GJJElVarYlLKXUF+gbEZunlIY0YiapGI88kqcgl1oKnn8eNtqo6ESSpCpWzhYVoyLibPK2FP99vTvmq2qkBNdcA6edBhtvDP36wY9/XHQqSVKVK6eE9QWeA54Eplc2jtTIpkyB44+H227LO+D36pXPgpQkqcLKKWGLppTOqHgSqbF9+WUuXoMGwTnn5Csh5yvngmFJkuZdOSWsf0TsllIaUPE0UmN55x3YYw/44AO46y7o2LHoRJKkFqacEnYicHZETAGmAAGklNISFU0mVcqgQXnX+1at8v5fW25ZdCJJUgtU79xLSmnxlNJ8KaWFU0pLlO5bwNQ83XYb/PrX8KMfwUsvWcAkSYWpt4RFdkhEnFu6v3JEbFr5aFIDmj49X/141FGwww75DMif/KToVJKkFqycVcg3ApsDB5XufwPcULFEUkP79ts8/XjVVflKyP79Yckli04lSWrhylkTtllKaeOIeAUgpfRVRCxY4VxSw/jkk7wD/vDhcN11cMIJRSeSJAkor4RNjYhWQAKIiNZATUVTSQ3h9ddh993hs8/g4YehXbuiE0mS9F/lTEd2A/4KLB8RFwPPA5dUNJU0r/7+d/jVr2DyZHj2WQuYJKnJqXckLKV0T0QMB3Ygb0/RIaX0ZsWTSXOrZ8+8AH/tteHRR2HVVYtOJEnS/yjn6si2wLiU0g0ppe7A2IjYrPLRpDmUEpx7Lhx+OGy7LQwebAGTJDVZ5UxH3kS+InKGb0uPSU3H5MlwyCFw0UXQuTMMGOAVkJKkJq2cEhYppTTjTkqphvIW9EuN44svYKed4N574eKL4dZbYYEFik4lSVKdyilT70XECfz/6NdxwHuViyTNgX/9C3bbDUaPziXswAOLTiRJUlnKGQk7FtgCGAeMBTYDjq5kKKksQ4ZA27bw+ef5akgLmCSpGalzJKy0P9jBKaUDGimPVJ4HHoCOHWHllfP6rzXXLDqRJElzpM6RsJTSdKB9I2WR6pcSXHkl7L8/bLJJHg2zgEmSmqFy1oQNjojuQB/ylZEApJRGVCyVNCvTp8PJJ8P11+cS1qsXLLxw0akkSZor5ZSwLUr/dq31WAK2b/g40mxMmpS3oPjLX+CUU+CKK2C+cpY0SpLUNJWzY/52jRFEmq0vvoD27eGFF+Caa+Ckk4pOJEnSPKu3hEXEebN6PKXUdVaPSw1q9GjYZZf8b58+sN9+RSeSJKlBlDMd+W2t2wsDewCeHanKe+WVvAfYd9/BwIGw1VZFJ5IkqcGUMx15Ve37EXEl0K9iiSSAxx+HffeFZZbJe4Cts07RiSRJalBzs7J5UeAnDR1E+q+ePWGPPWCNNfIWFBYwSVIVKmdN2D/IV0MCtAJa8/0rJaWGkVI++/Hcc2HHHeGhh2CJJYpOJUlSRZSzJmyPWrenAf9OKU2rUB61VNOmwfHHwy235J3wb7sNFlyw6FSSJFVMvdORKaUPgKWAPYG9AOeG1LC+/Rb22isXsLPOypuwWsAkSVWu3hIWEScC9wDLl77uiYjfVTqYWogvvoAddsjnP954I1xyCUQUnUqSpIorZzqyM7BZSulbgIi4HBgCXF/JYGoBPvwQdt4Z3n8fHnwwj4ZJktRClFPCAphe6/700mPS3Hv99VzAvvkGnngCtt666ESSJDWqckrYncBLEfHX0v0OwO2Vi6Sq98ILeQuKhRaCZ5+F9dcvOpEkSY2unM1ar46Ip4EtySNgh6eUXql0MFWpRx/NRw+tuGIeAVt99aITSZJUiNmWsIhYGDgW+CnwD+BGt6bQPOnVCzp3hg03zAvxl1++6ESSJBWmrqsjewFtyAVsV+DKRkmk6nTFFdCpE2y7LQwaZAGTJLV4dU1HrpNS+gVARNwOvNw4kVRVamrg97+Hq66C/feHu+7Ka8EkSWrh6iphU2fcSClNC/du0pyaOjVPP/buDV26wHXXwXxzc1ypJEnVp64StkFEjC/dDmCR0v0AUkrJQ/00exMn5gX4AwZA167whz+4CaskSbXMtoSllFo1ZhBVka+/zltQDBkCN98MxxxTdCJJkpqccvYJk8r36ad5E9bXX4c+fWDffYtOJElSk2QJU8P58EPYaScYMwYeeSSXMUmSNEuWMDWMd96BHXeE//wnb8K65ZZFJ5IkqUmzhGnejRyZR71Sgqefho02KjqRJElNnvsFaN4MHpw3YF1oIXjuOQuYJEllsoRp7j3xBPz613n3++efh7XXLjqRJEnNhiVMc+ehh/I2FGuumUfAVlml6ESSJDUrljDNuTvvzEcQtWmTz4H84Q+LTiRJUrNjCdOcue46OOKIfCXkwIGw9NJFJ5IkqVmyhKl8F10EJ50E++wD/frBYosVnUiSpGaroiUsInaJiLcjYlREnDmL50+JiDci4rWI+HtErFrJPJpLKeWzH889Fzp2hPvvz1dDSpKkuVaxEhYRrYAbgF2BdYADI2KdmV72CtAmpbQ+8CDwp0rl0VxKCU4/HS6+GI48Enr2hPndXk6SpHlVyZGwTYFRKaX3UkpTgPuB9rVfkFIalFKaWLr7IrBSBfNoTtXUwO9+B1ddBV26QI8eMJ8z2JIkNYRK/i/qisCYWvfHlh6bnc7A3yqYR3Ni+nQ45hi44QY47TTo1s0CJklSA6rkvFLM4rE0yxdGHAK0AbaZzfNHA0cDrOJ+VJU3bRocfjjcfXdeB3bhhRCz+jglSdLcquTQxlhg5Vr3VwI+mvlFEbEjcA7QLqU0eVZvlFK6JaXUJqXUpnXr1hUJq5KpU+Ggg3IBu+gi6NrVAiZJUgVUciRsKLBmRKwOjAMOAA6q/YKI2AjoAeySUvq0gllUjsmT8yas/frldWCnnFJ0IkmSqlbFSlhKaVpEdAEeB1oBd6SUXo+IrsCwlFI/4ArgB8ADkUdbPkwptatUJtVh0iTYe2947LG8Duy444pOJElSVavoXgMppQHAgJkeO6/W7R0r+fNVpkmToH17ePJJuO026Ny56ESSJFU9N3xq6WoXsDvugE6dik4kSVKL4J4DLZkFTJKkwjgS1lJNnJgL2N//DnfeCYcdVnQiSZJaFEtYSzRxIrRrB089ZQGTJKkglrCWZuJE2HNPGDQonwN56KFFJ5IkqUWyhLUktQtYr17QsWPRiSRJarFcmN9STJqUpyAtYJIkNQmWsJZg8mTYZ5+8BqxnTwuYJElNgNOR1W7qVDjgAPjb3+CWW1wDJklSE+FIWDWbPj2Xrocfhm7d4Kijik4kSZJKLGHVqqYmHz90//1w+eXwu98VnUiSJNViCatGKcHxx+cF+BdcAL//fdGJJEnSTCxh1SYlOOUUuPlmOOMMOO+8+r9HkiQ1OktYNUkJzjkHrr0WTjgBLr0UIopOJUmSZsESVk0uuigXr6OPzkXMAiZJUpNlCasW3brlqceOHeGmmyxgkiQ1cZawanD33XDiidChA9xxB8znxypJUlPn/1o3d/37Q6dOsN12cN99ML/770qS1BxYwpqz556D/faDDTfMG7IuvHDRiSRJUpksYc3VyJGwxx6w6qr5SKIllig6kSRJmgOWsObo3Xdh551hySVh4EBo3broRJIkaQ5ZwpqbceNgp53ysURPPAErr1x0IkmSNBdcxd2cfPllHgH74gsYNAh+9rOiE0mSpLlkCWsuJk3Ka8BGjcprwNq0KTqRJEmaB5aw5mD6dDj4YHjxRXjggbwdhSRJatYsYU1dSnDSSfDXv8J118E++xSdSJIkNQAX5jd1V10F3bvDKafkQ7klSVJVsIQ1ZfffD6efDvvvD1dcUXQaSZLUgCxhTdXTT8Nhh8FWW0GvXp4HKUlSlfF/2Zui11/Ph3GvsYbHEUmSVKUsYU3NJ5/ArrvCIovkrSiWWaboRJIkqQK8OrIpmTQJ2rfPm7E+91w+F1KSJFUlS1hTUVMDnTrB0KHwl7/AxhsXnUiSJFWQJaypuPBC+POf4fLL83owSZJU1VwT1hTcey907QqHH563pJAkSVXPEla0IUPgiCNg663h5pshouhEkiSpEVjCijR6dJ56XHnlvA5swQWLTiRJkhqJJawoEyfmAjZlCvTvD8suW3QiSZLUiFyYX4SU4Oij4bXXYMAAWHvtohNJkqRGZgkrQvfucM898Mc/wi67FJ1GkiQVwOnIxvb883DKKdCuHZx9dtFpJElSQSxhjemjj2C//WD11eGuuzyUW5KkFszpyMYyZUouYBMmwMCBsOSSRSeSJEkFsoQ1llNPhRdegD59YL31ik4jSZIK5nxYY7j33rwY/9RTYf/9i04jSZKaAEtYpb37LhxzDGy5JVx2WdFpJElSE2EJq6TJk+E3v8k74d97L8zv7K8kScpsBZX0+9/DK69A3775aCJJkqQSR8IqpW9f6NYNTjwx7wkmSZJUiyWsEsaOhcMPh403hssvLzqNJElqgixhDa2mBjp1yuvB7r8fFlqo6ESSJKkJck1YQ+veHf7+d7j5ZlhzzaLTSJKkJsqRsIb05ptwxhmw225w9NFFp5EkSU2YJayhTJ0KHTvCYovB7bdDRNGJJElSE+Z0ZEO56CIYPhweeghWWKHoNJIkqYlzJKwhvPIKXHwxHHoo7L130WkkSVIzYAmbV9OmwZFHwnLLwbXXFp1GkiQ1E05HzqtrroERI+CBB2DppYtOI0mSmglHwubFqFFw3nnQoQPss0/RaSRJUjNiCZtbKcExx+TDubt392pISZI0R5yOnFt9+sBTT+VNWVdcseg0kiSpmXEkbG5MmpQ3Zd1ww7woX5IkaQ45EjY3rrkGPvwQevWCVq2KTiNJkpohR8Lm1CefwKWX5sX4225bdBpJktRMWcLm1B/+AJMnwxVXFJ1EkiQ1Y5awOfHaa3DHHfC738FPf1p0GkmS1IxZwubEeefBkkvm0TBJkqR5YAkr1/Dh0LcvnHqqO+NLkqR5Zgkr1/nnwzLLwAknFJ1EkiRVAUtYOV56CR59FE47DZZYoug0kiSpCljCynHBBbDcctClS9FJJElSlbCE1ef11+Gxx+Dkk2HxxYtOI0mSqoQlrD7XXQcLL5wP65YkSWoglrC6fPEF9O4NHTvCsssWnUaSJFURS1hdbrkFvvvOKyIlSVKDs4TNTk0N9OgB228P661XdBpJklRlLGGz89xz8MEHcMQRRSeRJElVyBI2O3fdBT/4AXToUHSS/2vvzoPlqK47jn9/PAUJxGZAUYjArMIYHJCJDAgowuqAAUMcsUXl4EQORcouwDHBkKQoQyopbwTi2FZMYSBxYlYbAirCEgmBg0EggZ4WhIwssJHBILMvEUbo5I97BprRPG1o1E/Tv09V13Tfvt19T8/M01Hfnr5mZmbWg5yEdbJ0KdxwA4wfD8OH190aMzMz60FOwjqZOhVefRVOPrnulpiZmVmPchLWya23litghx1Wd0vMzMysRzkJaxcBkyfDUUeVh7SamZmZdUFXkzBJR0taIGmhpPM7rB8q6bpcP13STt1sz2rp74fFi+H44+tuiZmZmfWwriVhkvqAbwPHAHsCp0nas63aRODFiNgNuBT4arfas9qefx722guOPbbulpiZmVkP6+aVsP2AhRGxKCJ+A1wLnNBW5wTg33L+RuAISepim1btiCNg7lwYObLWZpiZmVlv62YSNgp4qrK8OMs61omIZcDLwAqDNEo6Q9IMSTOWLFnSpeaamZmZrT/dTMI6XdGKtahDRFweEWMjYuyIESPWSePMzMzM6tTNJGwxsENleXvg6YHqSBoCbAm80MU2mZmZmQ0K3UzCHgJGS9pZ0sbAqcAtbXVuAU7P+fHA1IhY4UqYmZmZWa8Z0q0dR8QySZ8H7gD6gCsjYp6ki4EZEXEL8D3g+5IWUq6Andqt9piZmZkNJl1LwgAi4jbgtrayCyvzS4GTutkGMzMzs8HIT8w3MzMzq4GTMDMzM7MaOAkzMzMzq4GTMDMzM7MaOAkzMzMzq4GTMDMzM7MaOAkzMzMzq4GTMDMzM7MaOAkzMzMzq4GTMDMzM7MaOAkzMzMzq4GTMDMzM7MaKCLqbsMakbQE+HmXD7Mt8OsuH2Mwa3L8TY4dmh1/k2OHZsff5Nih2fGvj9h3jIgRnVZscEnY+iBpRkSMrbsddWly/E2OHZodf5Njh2bH3+TYodnx1x27uyPNzMzMauAkzMzMzKwGTsI6u7zuBtSsyfE3OXZodvxNjh2aHX+TY4dmx19r7L4nzMzMzKwGvhJmZmZmVgMnYW0kHS1pgaSFks6vuz3dIOlKSc9Jmlsp21rSXZIez9cPZLkkfTPPx2xJ+9bX8vdP0g6S7pY0X9I8SWdnec/HL2mYpAcl9WfsF2X5zpKmZ+zXSdo4y4fm8sJcv1Od7V8XJPVJekTS5FxuUuxPSpojaZakGVnW85/7FklbSbpR0mP5/R/XhPglfSjf89b0iqRzmhB7i6Qv5N+8uZKuyb+Fg+K77ySsQlIf8G3gGGBP4DRJe9bbqq64Gji6rex8YEpEjAam5DKUczE6pzOASeupjd2yDPhiRHwYOAD4XL7HTYj/TeDwiNgHGAMcLekA4KvApRn7i8DErD8ReDEidgMuzXoburOB+ZXlJsUOcFhEjKn8JL8Jn/uWfwZuj4g9gH0on4Oejz8iFuR7Pgb4feAN4CYaEDuApFHAWcDYiPgI0AecymD57keEp5yAccAdzm7BEAAACcZJREFUleULgAvqbleXYt0JmFtZXgBsl/PbAQty/rvAaZ3q9cIE/BdwVNPiBzYFHgb2pzyocEiWv/MdAO4AxuX8kKynutv+PmLenvKPzeHAZEBNiT3jeBLYtq2sEZ97YAvgifb3sCnxV+L4OHBfk2IHRgFPAVvnd3ky8IeD5bvvK2Hv1XqzWhZnWROMjIhnAPL1t7O8Z89JXmb+KDCdhsSf3XGzgOeAu4CfAS9FxLKsUo3vndhz/cvANuu3xevUZcB5wPJc3obmxA4QwJ2SZko6I8sa8bkHdgGWAFdld/QVkobTnPhbTgWuyflGxB4RvwS+AfwCeIbyXZ7JIPnuOwl7L3Uoa/rPR3vynEjaDPghcE5EvLKyqh3KNtj4I+LtKN0S2wP7AR/uVC1feyZ2SccBz0XEzGpxh6o9F3vFQRGxL6W76XOSDllJ3V6LfwiwLzApIj4KvM673W+d9Fr85D1PnwRuWFXVDmUbbOx5r9sJwM7A7wLDKd+BdrV8952EvddiYIfK8vbA0zW1ZX17VtJ2APn6XJb33DmR9FuUBOw/I+JHWdyY+AEi4iVgGuW+uK0kDclV1fjeiT3Xbwm8sH5bus4cBHxS0pPAtZQuyctoRuwARMTT+foc5Z6g/WjO534xsDgipufyjZSkrCnxQ0k8Ho6IZ3O5KbEfCTwREUsi4i3gR8CBDJLvvpOw93oIGJ2/mtiYcun2lprbtL7cApye86dT7pVqlf9p/mLmAODl1iXsDZEkAd8D5kfEP1VW9Xz8kkZI2irnN6H8cZoP3A2Mz2rtsbfOyXhgauSNEhuaiLggIraPiJ0o3+upETGBBsQOIGm4pM1b85R7g+bSgM89QET8CnhK0oey6AjgURoSfzqNd7sioTmx/wI4QNKm+fe/9d4Pju9+3TfNDbYJ+ATwU8q9Mn9bd3u6FOM1lL7xtyhZ/0RKn/cU4PF83TrrivKL0Z8Bcyi/MKk9hvcR+8GUS8uzgVk5faIJ8QN7A49k7HOBC7N8F+BBYCGlq2Jolg/L5YW5fpe6Y1hH5+FQYHKTYs84+3Oa1/rb1oTPfeUcjAFm5Of/ZuADTYmf8kOc54EtK2WNiD1jugh4LP/ufR8YOli++35ivpmZmVkN3B1pZmZmVgMnYWZmZmY1cBJmZmZmVgMnYWZmZmY1cBJmZmZmVgMnYWaDnKSQdEll+VxJX15H+35tXexngH1PkzR21TV7j6QTc2D49XnMK9b2mJJ+8j6O29j32ez9chJmNvi9CXxK0rZ1HLzyVGlbfScC6y0Jk9QXEZ+NiEfXZvuIOHBdt8nMVs1JmNngtwy4HPhC+wpJO0qaIml2vn4wy6+WNEnS3ZIWSfoDSVdKmi/p6rZ9XCLp4dx+RJZNk/SPku4Bzs6n7f9Q0kM5HdShLZtIujbbch2wSWXdxyXdn8e5IcfubN9+N0n/I6k/6+2aT+3+uqS5kuZIOiXrHirpHknXS/qppK9ImiDpway3a+U8/KukH2e947J8mKSrsu4jkg7L8r1yH7MyjtFZfrPKwNfz9O7g10h6TdI/ZJsfkDRS0oGUMfq+nvvZNafbcx8/lrRHbn9SxtYv6d4O5+RQSfdKuknSoxnLRpVjXyxpOjCuekWqU7uyfGTuqz+nA1v1V+N4kyTNyHNwUXtbV/Y+5/vzaJ7Tb3Ta1qyR6n6SrSdPnlY+Aa8BWwBPUsYxOxf4cq67FTg95/8cuDnnr6aMkSjK4LWvAL9H+Y/XTGBM1gtgQs5fCHwr56cB36m04QfAwTn/QcqwT+3t/Cvgypzfm5I8jgW2Be4Fhue6L5FP62/bfjrwRzk/jPKU7z8G7gL6gJGUIUi2ozz1/qWcHwr8Ergotz0buKxyHm7PuEdTRogYBnwRuCrr7JH7HQb8S+V8bAxskvOtp4lvQnnq9jaV83d8zn8N+LvKccdXYpsCjM75/SlDoUB5IvmonN+qwzk5FFhKebp3X56L8ZVjn1ypO418uvlK2nUdZdB6cn9btj5jq3G8rSvbTQP2rh53oPcZ2BpYAO88HHyFOD15aurkK2FmG4CIeAX4d+CstlXjKAkSlOE4Dq6suzUigvIP/bMRMScillOGrdkp6yyn/MMM8B9t219XmT8S+JakWZSx1bZQjkVYcUjug4iYTRkeBsog4XsC9+X2pwM7VjfMfY2KiJty+6UR8Ua255qIeDvKwMP3AB/LzR6KiGci4k3KECt3ZvmcSnwA10fE8oh4HFhESboOzvNFRDwG/BzYHbgf+BtJXwJ2jIj/y32cJakfeIAyuO/oLP8NMDnnZ7YdtxXbZpQBg2/I+L9LSR4B7gOulvQXlOSmkwcjYlFEvE0Zcqz1Hr1NGYi+k4HadTgwKeN+OyJeXoPjnSzpYcrQV3uxYnfrQO/zK5TE7gpJnwLeGKDNZo3jez3MNhyXAQ8DV62kTnUcsjfzdXllvrU80He/uv3rlfmNgHGVpGR1jt8i4K6IOG0l22kNy2HFmKrxVuNrb1MMtN+I+EF27x0L3CHps7m/IynxvyFpGuWqGcBbmehCSYo6ndeNgJciYkyH450paf883ixJYyLi+Q7t7bS8NBOlTlanXQNZ4XiSdqZcgf1YRLyo0qU9rK3egO+zpP0oAyefCnyekgyaNZ6vhJltICLiBeB6yoDrLT+h/MMGMAH43zXc7UbA+Jz/k5VsfyflH08AJK2QUFC6oibk+o9QuiShXD06SNJuuW5TSbtXN8wrfYslnZh1hkraNPd5iqQ+lfvVDqEMqrsmTpK0Ud4ntgula6za1t0pXawLJO0CLIqIb1Ku+O1N6QJ+MROwPShXfFblVWDzSmxPSDopjydJ++T8rhExPSIuBH5NucrWbj9JO+e9Waew5u9x1RTgL/PYfZK2WM3jbUFJyl/O+8uO6bBdx/c5rwRuGRG3AedQBtI2M5yEmW1oLqHce9NyFvBnkmYDn6bcD7UmXgf2kjSTcnXi4gHqnQWMzRurHwXO7FBnErBZtuU8MlmKiCXAZ4Brct0DlC7Bdp+mdPvNpiSXvwPcROnW7AemAudFxK/WMMYFlG7M/wbOjIilwHeAPklzKN2un8luzVOAudmdtgelC/h2YEi26++z/atyLfDXKjf970pJ+CZml+Y8yn16UG7enyNpLiUx7O+wr/uBr1DuRXuCck7W1tnAYRn3TEq34iqPFxH9lG7IecCVlG7U91jJ+7w5MDnL7qHDD0zMmkrvXrE2M+st2W02OSJurLsta0PSocC5EXFcLx7PrOl8JczMzMysBr4SZmZmZlYDXwkzMzMzq4GTMDMzM7MaOAkzMzMzq4GTMDMzM7MaOAkzMzMzq4GTMDMzM7Ma/D8HyTmbejavcQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "scree = pca.explained_variance_ratio_*100\n",
    "#plt.bar(np.arange(len(scree))+1, scree)\n",
    "plt.plot(np.arange(len(scree)), np.cumsum(pca.explained_variance_ratio_), 'r-')\n",
    "plt.xlabel('Nombre de composantes principales')\n",
    "plt.ylabel('Pourcentage de la variance expliquee')\n",
    "plt.title(\"Eboulis des valeurs propres\")\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On enregistre les composantes dans une variable qui devient le nouveau x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34802, 800)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_projected.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportation données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exportation des données pour le fonctionnement de l'API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('tags.npy', pre_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['std_scale.plk']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(std_scale, 'std_scale.plk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_pca.plk']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pca, 'model_pca.plk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modélisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Base initiale:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_projected\n",
    "Y_train = y_train\n",
    "X_test = test_projected\n",
    "Y_test = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons crée une nouvelle base test et train afin de pouvoir tester la modélisation avant de réaliser la validation du modèle final sur la base test initiale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, X_test_2, Y_train_2, Y_test_2 = train_test_split(\n",
    "    X_train, Y_train, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Split base:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train_2\n",
    "Y = Y_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27841, 800)\n",
      "(27841,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_2.shape)\n",
    "print(Y_train_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Base échantillon:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour tester le bon fonctionnement des modèles, nous avons créer une nouvelle base train-test_E à partir des 10 000 première valeurs de X_train et Y_train. Cela permet de pouvoir faire tourner les algorithmes plus facilement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_E, X_test_E, Y_train_E, Y_test_E = train_test_split(\n",
    "    X_train[:10000], Y_train[:10000], test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V1 - Modélisation sur un échantillon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons tester trois modèles différents pour trouver celui ayant la meilleure précision. Les trois modèles choisis sont:\n",
    "- l'arbre de décision\n",
    "- le modèle logisitique\n",
    "- la SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Ces tests sont effectués sur un échantillon de données pour pouvoir faire exécuter les modèles. Cependant le résultat de ces tests là ne sont pas pris en compte dans le choix du modèle final, ils permettent uniquement de vérifier le bon fonctionnement des modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choix des données d'entrainement\n",
    "X = X_train_E\n",
    "Y = Y_train_E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbre de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_class = DecisionTreeClassifier()\n",
    "tree_class.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.344\n",
      "0.14479324281992892\n",
      "0.1402413575967063\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        35\n",
      "           3       0.00      0.00      0.00         2\n",
      "           5       0.52      0.52      0.52       187\n",
      "          13       0.00      0.00      0.00         3\n",
      "          23       0.27      0.38      0.31        34\n",
      "          24       0.30      0.30      0.30       247\n",
      "          26       0.42      0.37      0.40       148\n",
      "          33       0.30      0.25      0.27        40\n",
      "          38       0.00      0.00      0.00         2\n",
      "          39       0.00      0.00      0.00         1\n",
      "          49       0.73      0.69      0.71        65\n",
      "          51       0.00      0.00      0.00         0\n",
      "          55       0.20      0.21      0.21        56\n",
      "          59       0.00      0.00      0.00         1\n",
      "          63       0.33      0.27      0.30       100\n",
      "          66       0.09      0.13      0.11        38\n",
      "          70       0.34      0.38      0.36       230\n",
      "          71       0.33      0.32      0.32       222\n",
      "          73       0.14      0.16      0.15        43\n",
      "          78       0.00      0.00      0.00         0\n",
      "          81       0.39      0.33      0.36        42\n",
      "          83       0.00      0.00      0.00         1\n",
      "          84       0.00      0.00      0.00        25\n",
      "          87       0.15      0.20      0.17        92\n",
      "          88       0.00      0.00      0.00         1\n",
      "          89       0.00      0.00      0.00         1\n",
      "          90       0.48      0.51      0.50       244\n",
      "          92       0.11      0.05      0.07        38\n",
      "          93       0.22      0.23      0.22        44\n",
      "          94       0.00      0.00      0.00         0\n",
      "          96       0.00      0.00      0.00         0\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       0.46      0.30      0.36        54\n",
      "         102       0.00      0.00      0.00         1\n",
      "         104       0.00      0.00      0.00         0\n",
      "         108       0.00      0.00      0.00         0\n",
      "         109       0.00      0.00      0.00         1\n",
      "         111       0.00      0.00      0.00         1\n",
      "         120       0.00      0.00      0.00         1\n",
      "         124       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.34      2000\n",
      "   macro avg       0.14      0.14      0.14      2000\n",
      "weighted avg       0.35      0.34      0.34      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "Y_pred = tree_class.predict(X_test_E)\n",
    "\n",
    "print(f1_score(Y_test_E, Y_pred, average='micro'))\n",
    "print(precision_score(Y_test_E, Y_pred, average=\"macro\"))\n",
    "print(recall_score(Y_test_E, Y_pred, average=\"macro\"))\n",
    "print(classification_report(Y_test_E, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5875\n",
      "0.330346042482038\n",
      "0.3147159592516945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.26      0.24        35\n",
      "           3       0.00      0.00      0.00         2\n",
      "           5       0.60      0.62      0.61       187\n",
      "          13       0.00      0.00      0.00         3\n",
      "          23       0.31      0.47      0.37        34\n",
      "          24       0.59      0.65      0.62       247\n",
      "          26       0.59      0.53      0.56       148\n",
      "          33       0.47      0.38      0.42        40\n",
      "          38       0.00      0.00      0.00         2\n",
      "          39       0.00      0.00      0.00         1\n",
      "          49       0.91      0.74      0.81        65\n",
      "          55       0.37      0.39      0.38        56\n",
      "          59       0.00      0.00      0.00         1\n",
      "          63       0.62      0.55      0.59       100\n",
      "          66       0.17      0.18      0.18        38\n",
      "          70       0.59      0.65      0.62       230\n",
      "          71       0.58      0.59      0.59       222\n",
      "          73       0.42      0.49      0.45        43\n",
      "          81       0.71      0.52      0.60        42\n",
      "          83       0.00      0.00      0.00         1\n",
      "          84       0.12      0.08      0.10        25\n",
      "          87       0.56      0.65      0.60        92\n",
      "          88       0.00      0.00      0.00         1\n",
      "          89       0.00      0.00      0.00         1\n",
      "          90       0.78      0.79      0.78       244\n",
      "          92       0.65      0.34      0.45        38\n",
      "          93       0.68      0.64      0.66        44\n",
      "          99       0.61      0.56      0.58        54\n",
      "         102       0.00      0.00      0.00         1\n",
      "         109       0.00      0.00      0.00         1\n",
      "         111       0.00      0.00      0.00         1\n",
      "         120       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.59      2000\n",
      "   macro avg       0.33      0.31      0.32      2000\n",
      "weighted avg       0.59      0.59      0.59      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "Y_pred = log_reg.predict(X_test_E)\n",
    "\n",
    "print(f1_score(Y_test_E, Y_pred, average='micro'))\n",
    "print(precision_score(Y_test_E, Y_pred, average=\"macro\"))\n",
    "print(recall_score(Y_test_E, Y_pred, average=\"macro\"))\n",
    "print(classification_report(Y_test_E, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6235\n",
      "0.3903087821835974\n",
      "0.2874000660722521\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        35\n",
      "           3       0.00      0.00      0.00         2\n",
      "           5       0.73      0.76      0.74       187\n",
      "          13       0.00      0.00      0.00         3\n",
      "          23       0.75      0.18      0.29        34\n",
      "          24       0.49      0.72      0.58       247\n",
      "          26       0.76      0.61      0.67       148\n",
      "          33       0.42      0.25      0.31        40\n",
      "          38       0.00      0.00      0.00         2\n",
      "          39       0.00      0.00      0.00         1\n",
      "          49       0.83      0.69      0.76        65\n",
      "          55       0.35      0.21      0.27        56\n",
      "          59       0.00      0.00      0.00         1\n",
      "          63       0.67      0.62      0.65       100\n",
      "          66       1.00      0.08      0.15        38\n",
      "          70       0.54      0.75      0.63       230\n",
      "          71       0.54      0.77      0.63       222\n",
      "          73       0.57      0.09      0.16        43\n",
      "          81       0.96      0.52      0.68        42\n",
      "          83       0.00      0.00      0.00         1\n",
      "          84       0.00      0.00      0.00        25\n",
      "          87       0.83      0.58      0.68        92\n",
      "          88       0.00      0.00      0.00         1\n",
      "          89       0.00      0.00      0.00         1\n",
      "          90       0.75      0.84      0.79       244\n",
      "          92       0.87      0.34      0.49        38\n",
      "          93       0.83      0.57      0.68        44\n",
      "          99       0.61      0.61      0.61        54\n",
      "         102       0.00      0.00      0.00         1\n",
      "         109       0.00      0.00      0.00         1\n",
      "         111       0.00      0.00      0.00         1\n",
      "         120       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.62      2000\n",
      "   macro avg       0.39      0.29      0.30      2000\n",
      "weighted avg       0.63      0.62      0.60      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "Y_pred = svm.predict(X_test_E)\n",
    "\n",
    "print(f1_score(Y_test_E, Y_pred, average='micro'))\n",
    "print(precision_score(Y_test_E, Y_pred, average=\"macro\"))\n",
    "print(recall_score(Y_test_E, Y_pred, average=\"macro\"))\n",
    "print(classification_report(Y_test_E, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modélisation sur toutes les données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois que nous avons vérifié que les modèles fonctionnent, les tests pour trouver le modèle le plus adapté sont lancés sur toutes les données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests sur google colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le jeu de données étant très important, j'ai rencontré des difficultées à faire tourner ces codes sur jupyter. J'ai donc fait certains tests sur google colab en utilisant le GPU. Pour pouvoir faire cela, il m'a fallu transférer les données sur google colab et vérifier leur forme et leur taille."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train_2\n",
    "Y = Y_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27900, 800)\n",
      "(27900,)\n",
      "(6976, 800)\n",
      "(6976,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(X_test_2.shape)\n",
    "print(Y_test_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [[ 0.6308673  -1.29475411 -2.48500474 ... -1.57374487 -0.28336823\n",
      "  -1.37927146]\n",
      " [-0.47473237 -1.2811054  -0.13240925 ... -0.85725817  0.27135341\n",
      "   0.07065494]\n",
      " [-3.44883561  0.4801291  -1.097162   ... -0.62238276  0.02870844\n",
      "  -2.86407701]\n",
      " ...\n",
      " [-0.60307577  1.32995904  1.60713454 ...  0.40832189  0.5182883\n",
      "  -0.22438643]\n",
      " [ 0.03098465 -2.50835725  3.99099541 ...  0.97028402  0.32447122\n",
      "  -0.59510646]\n",
      " [ 0.15557146  0.48820484 -0.30835538 ...  1.19139354  0.8639742\n",
      "   1.84410017]]\n",
      "Y: [71 90 90 ... 70 26 87]\n",
      "X_test_2: [[ 4.10706023e+00 -1.35589932e+00 -3.85813274e+00 ...  4.20535336e-01\n",
      "  -1.25037205e+00 -1.29945165e+00]\n",
      " [ 1.53820732e+00  6.53139347e-03 -6.72654005e-01 ... -1.06890883e-02\n",
      "  -1.11226497e+00 -7.68421269e-02]\n",
      " [-3.51798866e+00  1.03986573e+00 -1.13900036e+00 ...  5.22231805e-01\n",
      "  -6.74840348e-01  1.43773371e+00]\n",
      " ...\n",
      " [-7.61737691e-01 -1.36831669e+00  3.27620734e+00 ...  3.55936404e-01\n",
      "  -1.46203278e+00 -4.76016808e-02]\n",
      " [-1.93316048e+00 -1.49257989e+00  4.67835337e-01 ...  1.46017333e+00\n",
      "   1.99807109e+00  8.89231284e-01]\n",
      " [ 6.83195468e+00  2.27618033e+00  6.16898093e+00 ...  1.00148342e+00\n",
      "  -1.02686277e+00  9.68583215e-01]]\n",
      "Y_test_2: [55 66 92 ... 26 66  5]\n"
     ]
    }
   ],
   "source": [
    "print('X:', X)\n",
    "print('Y:', Y)\n",
    "print('X_test_2:', X_test_2)\n",
    "print('Y_test_2:', Y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde des données pour utiliser dans google colab\n",
    "np.savetxt('X.csv', X, delimiter=',', fmt='%d', header='Values')\n",
    "np.savetxt('Y.csv', y, delimiter=',', fmt='%d', header='Values')\n",
    "np.savetxt('X_test_2.csv', X_test_2, delimiter=',', fmt='%d', header='Values')\n",
    "np.savetxt('Y_test_2.csv', Y_test_2, delimiter=',', fmt='%d', header='Values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choix du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choix des données d'entrainement\n",
    "X = X_train_2\n",
    "Y = Y_train_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arbre de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38775802752293576\n",
      "0.10329050122795348\n",
      "0.10377419275314687\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.10      0.10       112\n",
      "           1       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         1\n",
      "           5       0.52      0.52      0.52       632\n",
      "           6       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         3\n",
      "          13       0.00      0.00      0.00         8\n",
      "          14       0.00      0.00      0.00         2\n",
      "          22       0.00      0.00      0.00         1\n",
      "          23       0.24      0.23      0.23       170\n",
      "          24       0.35      0.34      0.35       813\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.48      0.47      0.47       467\n",
      "          28       0.00      0.00      0.00         2\n",
      "          32       0.00      0.00      0.00         0\n",
      "          33       0.19      0.24      0.21       108\n",
      "          36       0.00      0.00      0.00         1\n",
      "          38       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         1\n",
      "          47       0.00      0.00      0.00         1\n",
      "          49       0.77      0.77      0.77       214\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.00      0.00      0.00         1\n",
      "          53       0.00      0.00      0.00         1\n",
      "          55       0.24      0.22      0.23       208\n",
      "          57       0.00      0.00      0.00         0\n",
      "          59       0.00      0.00      0.00         2\n",
      "          62       0.00      0.00      0.00         1\n",
      "          63       0.26      0.27      0.27       278\n",
      "          65       0.00      0.00      0.00         1\n",
      "          66       0.13      0.13      0.13       134\n",
      "          67       0.00      0.00      0.00         1\n",
      "          70       0.44      0.41      0.43       923\n",
      "          71       0.41      0.43      0.42       851\n",
      "          73       0.19      0.22      0.20       138\n",
      "          75       0.00      0.00      0.00         1\n",
      "          76       0.00      0.00      0.00         1\n",
      "          77       0.00      0.00      0.00         1\n",
      "          78       0.00      0.00      0.00         2\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         1\n",
      "          81       0.29      0.26      0.27       151\n",
      "          82       0.00      0.00      0.00         0\n",
      "          84       0.03      0.03      0.03        74\n",
      "          87       0.22      0.22      0.22       362\n",
      "          89       0.00      0.00      0.00         0\n",
      "          90       0.55      0.57      0.56       845\n",
      "          92       0.17      0.16      0.16       112\n",
      "          93       0.27      0.25      0.26       174\n",
      "          95       0.00      0.00      0.00         1\n",
      "          96       0.00      0.00      0.00         0\n",
      "          99       0.35      0.38      0.37       154\n",
      "         101       0.00      0.00      0.00         1\n",
      "         102       0.00      0.00      0.00         1\n",
      "         105       0.00      0.00      0.00         0\n",
      "         107       0.00      0.00      0.00         1\n",
      "         114       0.00      0.00      0.00         1\n",
      "         120       0.00      0.00      0.00        11\n",
      "         124       0.00      0.00      0.00         4\n",
      "         125       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.39      6976\n",
      "   macro avg       0.10      0.10      0.10      6976\n",
      "weighted avg       0.39      0.39      0.39      6976\n",
      "\n",
      "Temps d'exécution:  101.86959886550903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "debut_tree = time.time()\n",
    "\n",
    "tree_class = DecisionTreeClassifier()\n",
    "tree_class.fit(X, Y)\n",
    "\n",
    "Y_pred = tree_class.predict(X_test_2)\n",
    "\n",
    "fin_tree =  time.time()\n",
    "print(f1_score(Y_test_2, Y_pred, average='micro'))\n",
    "print(precision_score(Y_test_2, Y_pred, average=\"macro\"))\n",
    "print(recall_score(Y_test_2, Y_pred, average=\"macro\"))\n",
    "print(classification_report(Y_test_2, Y_pred))\n",
    "print(\"Temps d'exécution: \", fin_tree - debut_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6619839449541285\n",
      "0.22558681990384988\n",
      "0.21316928210633107\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.22      0.23       112\n",
      "           1       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         1\n",
      "           5       0.80      0.75      0.77       632\n",
      "           9       0.00      0.00      0.00         3\n",
      "          11       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         8\n",
      "          14       0.00      0.00      0.00         2\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         1\n",
      "          23       0.42      0.41      0.41       170\n",
      "          24       0.64      0.65      0.65       813\n",
      "          26       0.67      0.69      0.68       467\n",
      "          28       0.00      0.00      0.00         2\n",
      "          33       0.31      0.37      0.34       108\n",
      "          36       0.00      0.00      0.00         1\n",
      "          44       0.00      0.00      0.00         1\n",
      "          47       0.00      0.00      0.00         1\n",
      "          49       0.85      0.88      0.87       214\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.00      0.00      0.00         1\n",
      "          53       0.00      0.00      0.00         1\n",
      "          55       0.44      0.47      0.46       208\n",
      "          59       0.00      0.00      0.00         2\n",
      "          62       0.00      0.00      0.00         1\n",
      "          63       0.54      0.60      0.57       278\n",
      "          65       0.00      0.00      0.00         1\n",
      "          66       0.29      0.27      0.28       134\n",
      "          67       0.00      0.00      0.00         1\n",
      "          70       0.76      0.72      0.74       923\n",
      "          71       0.73      0.70      0.72       851\n",
      "          73       0.36      0.45      0.40       138\n",
      "          75       0.00      0.00      0.00         1\n",
      "          76       0.00      0.00      0.00         1\n",
      "          77       0.00      0.00      0.00         1\n",
      "          78       0.00      0.00      0.00         2\n",
      "          80       0.00      0.00      0.00         1\n",
      "          81       0.62      0.60      0.61       151\n",
      "          82       0.00      0.00      0.00         0\n",
      "          84       0.15      0.22      0.17        74\n",
      "          87       0.71      0.65      0.68       362\n",
      "          90       0.84      0.84      0.84       845\n",
      "          92       0.58      0.62      0.60       112\n",
      "          93       0.66      0.63      0.64       174\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         1\n",
      "          97       0.00      0.00      0.00         0\n",
      "          99       0.58      0.66      0.62       154\n",
      "         101       0.00      0.00      0.00         1\n",
      "         102       0.00      0.00      0.00         1\n",
      "         107       0.00      0.00      0.00         1\n",
      "         114       0.00      0.00      0.00         1\n",
      "         120       1.00      0.09      0.17        11\n",
      "         124       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.66      6976\n",
      "   macro avg       0.23      0.21      0.21      6976\n",
      "weighted avg       0.67      0.66      0.66      6976\n",
      "\n",
      "Temps d'exécution:  24.22258186340332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "debut_reg = time.time()\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X, Y)\n",
    "Y_pred = log_reg.predict(X_test_2)\n",
    "\n",
    "fin_reg = time.time()\n",
    "print(f1_score(Y_test_2, Y_pred, average='micro'))\n",
    "print(precision_score(Y_test_2, Y_pred, average=\"macro\"))\n",
    "print(recall_score(Y_test_2, Y_pred, average=\"macro\"))\n",
    "print(classification_report(Y_test_2, Y_pred))\n",
    "print(\"Temps d'exécution: \", fin_reg - debut_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6810493119266054\n",
      "0.266716028212696\n",
      "0.22460081729901948\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.03      0.05       112\n",
      "           1       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         1\n",
      "           5       0.77      0.81      0.79       632\n",
      "           9       0.00      0.00      0.00         3\n",
      "          13       0.00      0.00      0.00         8\n",
      "          14       0.00      0.00      0.00         2\n",
      "          22       0.00      0.00      0.00         1\n",
      "          23       0.71      0.29      0.41       170\n",
      "          24       0.53      0.76      0.63       813\n",
      "          26       0.71      0.72      0.72       467\n",
      "          28       0.00      0.00      0.00         2\n",
      "          33       0.40      0.40      0.40       108\n",
      "          36       0.00      0.00      0.00         1\n",
      "          44       0.00      0.00      0.00         1\n",
      "          47       0.00      0.00      0.00         1\n",
      "          49       0.91      0.90      0.91       214\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.00      0.00      0.00         1\n",
      "          53       0.00      0.00      0.00         1\n",
      "          55       0.51      0.50      0.51       208\n",
      "          59       0.00      0.00      0.00         2\n",
      "          62       0.00      0.00      0.00         1\n",
      "          63       0.57      0.66      0.61       278\n",
      "          65       0.00      0.00      0.00         1\n",
      "          66       0.51      0.14      0.22       134\n",
      "          67       0.00      0.00      0.00         1\n",
      "          70       0.67      0.72      0.69       923\n",
      "          71       0.68      0.79      0.74       851\n",
      "          73       0.51      0.24      0.33       138\n",
      "          75       0.00      0.00      0.00         1\n",
      "          76       0.00      0.00      0.00         1\n",
      "          77       0.00      0.00      0.00         1\n",
      "          78       0.00      0.00      0.00         2\n",
      "          80       0.00      0.00      0.00         1\n",
      "          81       0.76      0.64      0.69       151\n",
      "          84       0.40      0.03      0.05        74\n",
      "          87       0.84      0.59      0.69       362\n",
      "          90       0.80      0.85      0.83       845\n",
      "          92       0.79      0.59      0.67       112\n",
      "          93       0.86      0.59      0.70       174\n",
      "          95       0.00      0.00      0.00         1\n",
      "          99       0.64      0.76      0.69       154\n",
      "         101       0.00      0.00      0.00         1\n",
      "         102       0.00      0.00      0.00         1\n",
      "         107       0.00      0.00      0.00         1\n",
      "         114       0.00      0.00      0.00         1\n",
      "         120       0.00      0.00      0.00        11\n",
      "         124       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.68      6976\n",
      "   macro avg       0.27      0.22      0.23      6976\n",
      "weighted avg       0.68      0.68      0.66      6976\n",
      "\n",
      "Temps d'éxecution:  1478.547325372696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "debut_svm = time.time()\n",
    "\n",
    "svm = SVC()\n",
    "svm.fit(X, Y)\n",
    "Y_pred = svm.predict(X_test_2)\n",
    "\n",
    "fin_svm = time.time()\n",
    "print(f1_score(Y_test_2, Y_pred, average='micro'))\n",
    "print(precision_score(Y_test_2, Y_pred, average=\"macro\"))\n",
    "print(recall_score(Y_test_2, Y_pred, average=\"macro\"))\n",
    "print(classification_report(Y_test_2, Y_pred))\n",
    "print(\"Temps d'éxecution: \", fin_svm - debut_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle choisi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le meilleur score est atteint avec la SVM (accuracy = 0,68). Cependant le temps d'exécution de la SVM est plus de 60 fois plus long que pour la régression linéaire qui possède un score de 0,66.\n",
    "Le modèle choisi est donc la régression logistique avec un score accuracy de 0,66 avec les paramètres par défaut suivants: _{'C': 1, 'max_iter': 100, 'penalty': 'l2'}._\n",
    "\n",
    "On teste d'autres paramètres pour améliorer si possible le score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choix des données d'entrainement\n",
    "X = X_train_2\n",
    "Y = Y_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choix du modèle\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning des paramètres : GridSearchCV V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:672: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  7.1min finished\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'penalty': ['l1', 'none'],\n",
    "    'C': [1, 10, 100],\n",
    "    'max_iter': [100, 150]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid,\n",
    "                           cv=5, scoring=\"accuracy\", verbose=2, n_jobs=-1)\n",
    "\n",
    "best_model = grid_search.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'max_iter': 100, 'penalty': 'none'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6280645161290322"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning des paramètres : GridSearchCV V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:672: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed: 26.7min finished\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [1, 10],\n",
    "    'max_iter': [100, 1000]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid,\n",
    "                           cv=5, scoring=\"accuracy\", verbose=2, n_jobs=-1)\n",
    "best_model = grid_search.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'max_iter': 100, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6470967741935484"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning des paramètres : GridSearchCV V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:672: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 16.0min finished\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'penalty': ['l2', 'none'],\n",
    "     'C': np.logspace(-2,2,5),\n",
    "    'max_iter': [50,100]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring=\"accuracy\", verbose=2, n_jobs=-1)\n",
    "best_model = grid_search.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meilleurs paramètres: {'C': 0.01, 'max_iter': 100, 'penalty': 'l2'}\n",
    "\n",
    "Meilleur score: 0.7102879303541482"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.01, 'max_iter': 100, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7040143369175628"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning des paramètres : GridSearchCV V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:672: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 20.0min\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed: 94.6min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'penalty': ['l2', 'none'],\n",
    "     'C': np.logspace(-1,2,4),\n",
    "    'max_iter': [100,1000]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring=\"accuracy\", verbose=2, n_jobs=-1)\n",
    "best_model = grid_search.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'max_iter': 1000, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6757347670250896"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meilleurs paramètres: {'C': 0.1, 'max_iter': 1000, 'penalty': 'l2'}\n",
    "Meilleur score: 0.6458596765972839"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paramètres choisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir testé différents paramètres, le meilleur score est obtenu dans le tuning V3 avec C=0,01, penalty=l2 et max_tier=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.10      0.15       122\n",
      "           1       0.00      0.00      0.00         1\n",
      "           3       0.78      0.82      0.80       749\n",
      "           9       0.00      0.00      0.00        13\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.41      0.38      0.39       176\n",
      "          13       0.67      0.74      0.70      1077\n",
      "          14       0.71      0.71      0.71       593\n",
      "          16       0.00      0.00      0.00         1\n",
      "          24       0.00      0.00      0.00         1\n",
      "          25       0.48      0.41      0.45       155\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.00      0.00      0.00         1\n",
      "          30       0.00      0.00      0.00         1\n",
      "          33       0.00      0.00      0.00         1\n",
      "          34       0.00      0.00      0.00         7\n",
      "          36       0.00      0.00      0.00         1\n",
      "          40       0.00      0.00      0.00         1\n",
      "          43       0.00      0.00      0.00         1\n",
      "          44       0.00      0.00      0.00         1\n",
      "          45       0.00      0.00      0.00         1\n",
      "          46       0.89      0.89      0.89       264\n",
      "          48       0.00      0.00      0.00         1\n",
      "          53       0.45      0.54      0.49       236\n",
      "          54       0.00      0.00      0.00         1\n",
      "          55       0.00      0.00      0.00         3\n",
      "          56       0.00      0.00      0.00         1\n",
      "          58       0.59      0.74      0.66       322\n",
      "          59       0.00      0.00      0.00         1\n",
      "          60       0.44      0.29      0.35       183\n",
      "          63       0.72      0.75      0.73      1115\n",
      "          65       0.74      0.79      0.76      1127\n",
      "          66       0.45      0.41      0.43       163\n",
      "          69       0.00      0.00      0.00         1\n",
      "          75       0.73      0.72      0.72       176\n",
      "          76       0.00      0.00      0.00         1\n",
      "          78       0.00      0.00      0.00         1\n",
      "          79       0.44      0.17      0.25       109\n",
      "          80       0.00      0.00      0.00         1\n",
      "          81       0.79      0.68      0.73       434\n",
      "          83       0.00      0.00      0.00         1\n",
      "          84       0.86      0.89      0.87      1108\n",
      "          86       0.66      0.57      0.61       107\n",
      "          87       0.78      0.69      0.73       206\n",
      "          97       0.71      0.68      0.70       213\n",
      "         103       0.00      0.00      0.00         2\n",
      "         104       0.00      0.00      0.00         1\n",
      "         107       0.00      0.00      0.00         1\n",
      "         108       0.00      0.00      0.00         1\n",
      "         110       0.00      0.00      0.00         1\n",
      "         113       0.00      0.00      0.00         1\n",
      "         115       0.00      0.00      0.00         1\n",
      "         116       0.00      0.00      0.00         3\n",
      "         118       0.00      0.00      0.00         1\n",
      "         119       0.00      0.00      0.00         1\n",
      "         120       0.00      0.00      0.00         1\n",
      "         121       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.71      8696\n",
      "   macro avg       0.22      0.21      0.21      8696\n",
      "weighted avg       0.70      0.71      0.70      8696\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_final = LogisticRegression(penalty='l2', C=0.01, max_iter=100)\n",
    "model_final.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = model_final.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_final.plk']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exportation du modèle final\n",
    "joblib.dump(model_final, 'model_final.plk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "168px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
