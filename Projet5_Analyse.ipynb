{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet 5 - Catégorisez automatiquement des questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des librairies et des données et conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import scipy\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import csv\n",
    "from sklearn import preprocessing\n",
    "from sklearn import decomposition\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_validate\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix, plot_confusion_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mx = pd.read_csv('test_mx.csv', sep=';', index_col=0)\n",
    "train_mx = pd.read_csv('train_mx.csv', sep=';', index_col=0)\n",
    "fw_dict = pd.read_csv('fw_dict.csv')\n",
    "test_df = pd.read_csv('processed_test_df.csv', sep=';',\n",
    "                      index_col=0, converters={'processed_tags': eval})\n",
    "train_df = pd.read_csv('processed_train_df.csv', sep=';',\n",
    "                       index_col=0, converters={'processed_tags': eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = []\n",
    "with open('feature_name.csv', 'r') as data:\n",
    "    for line in csv.reader(data):\n",
    "        feature_name.append(line)\n",
    "\n",
    "# Transforme la liste de listes en liste\n",
    "feature_names = [item for sublist in feature_name for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw_dict = fw_dict.to_dict(orient='list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>according</th>\n",
       "      <th>account</th>\n",
       "      <th>achieve</th>\n",
       "      <th>across</th>\n",
       "      <th>action</th>\n",
       "      <th>active</th>\n",
       "      <th>activity</th>\n",
       "      <th>...</th>\n",
       "      <th>xcode</th>\n",
       "      <th>xml</th>\n",
       "      <th>xmlns</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>z</th>\n",
       "      <th>zero</th>\n",
       "      <th>zip</th>\n",
       "      <th>zygoteinit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.115881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.18369</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34873</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.053969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34876 rows × 977 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           able    accept    access  according  account  achieve  across  \\\n",
       "0      0.000000  0.000000  0.000000   0.000000      0.0      0.0     0.0   \n",
       "1      0.000000  0.000000  0.000000   0.000000      0.0      0.0     0.0   \n",
       "2      0.115881  0.000000  0.000000   0.000000      0.0      0.0     0.0   \n",
       "3      0.000000  0.000000  0.000000   0.000000      0.0      0.0     0.0   \n",
       "4      0.000000  0.000000  0.000000   0.000000      0.0      0.0     0.0   \n",
       "...         ...       ...       ...        ...      ...      ...     ...   \n",
       "34871  0.000000  0.000000  0.000000   0.000000      0.0      0.0     0.0   \n",
       "34872  0.000000  0.000000  0.081002   0.000000      0.0      0.0     0.0   \n",
       "34873  0.000000  0.235645  0.000000   0.108872      0.0      0.0     0.0   \n",
       "34874  0.000000  0.000000  0.000000   0.000000      0.0      0.0     0.0   \n",
       "34875  0.000000  0.000000  0.000000   0.000000      0.0      0.0     0.0   \n",
       "\n",
       "       action  active  activity  ...  xcode      xml     xmlns  year  yes  \\\n",
       "0         0.0     0.0       0.0  ...    0.0  0.00000  0.000000   0.0  0.0   \n",
       "1         0.0     0.0       0.0  ...    0.0  0.00000  0.000000   0.0  0.0   \n",
       "2         0.0     0.0       0.0  ...    0.0  0.00000  0.000000   0.0  0.0   \n",
       "3         0.0     0.0       0.0  ...    0.0  0.00000  0.000000   0.0  0.0   \n",
       "4         0.0     0.0       0.0  ...    0.0  0.18369  0.000000   0.0  0.0   \n",
       "...       ...     ...       ...  ...    ...      ...       ...   ...  ...   \n",
       "34871     0.0     0.0       0.0  ...    0.0  0.00000  0.000000   0.0  0.0   \n",
       "34872     0.0     0.0       0.0  ...    0.0  0.00000  0.000000   0.0  0.0   \n",
       "34873     0.0     0.0       0.0  ...    0.0  0.00000  0.000000   0.0  0.0   \n",
       "34874     0.0     0.0       0.0  ...    0.0  0.00000  0.000000   0.0  0.0   \n",
       "34875     0.0     0.0       0.0  ...    0.0  0.00000  0.053969   0.0  0.0   \n",
       "\n",
       "            yet    z  zero  zip  zygoteinit  \n",
       "0      0.000000  0.0   0.0  0.0         0.0  \n",
       "1      0.000000  0.0   0.0  0.0         0.0  \n",
       "2      0.000000  0.0   0.0  0.0         0.0  \n",
       "3      0.000000  0.0   0.0  0.0         0.0  \n",
       "4      0.000000  0.0   0.0  0.0         0.0  \n",
       "...         ...  ...   ...  ...         ...  \n",
       "34871  0.000000  0.0   0.0  0.0         0.0  \n",
       "34872  0.000000  0.0   0.0  0.0         0.0  \n",
       "34873  0.000000  0.0   0.0  0.0         0.0  \n",
       "34874  0.000000  0.0   0.0  0.0         0.0  \n",
       "34875  0.025111  0.0   0.0  0.0         0.0  \n",
       "\n",
       "[34876 rows x 977 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = scipy.sparse.csr_matrix(train_mx.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<34876x977 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1051739 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(learning_method='online', learning_offset=50.0,\n",
       "                          max_iter=5, n_components=11, random_state=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=11, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "\n",
    "lda.fit(train_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in LDA model: \n",
      "Topic #0:\n",
      "use javascript using would page like code way file j know html browser c jquery function window application one google need example time want image work question good java find script web chrome event used user library get net looking\n",
      "Topic #1:\n",
      "public thread class method exception static void task java catch private new system difference async throw test interface null println try return string block queue object code main call e final instance wait console boolean writeline args run override int\n",
      "Topic #2:\n",
      "java android org jar eclipse com gradle maven spring annotation dependency hibernate lang junit xml bean compile build support google plugin apache sun class project util internal springframework version activitythread servlet jdk test http main error source property v groupid\n",
      "Topic #3:\n",
      "android view layout button image activity app self color intent item text id io screen height swift fragment want width parent r background set change textview action bar programmatically new dialog animation notification show drawable size application keyboard like menu\n",
      "Topic #4:\n",
      "date input datetime form jquery button value text event click day function option time td javascript div label element format select month type id field html get mm submit name checkbox want var hour using alert child box year tr\n",
      "Topic #5:\n",
      "file python error project version app run install studio android c path application build window directory module package py using command library get xcode code running test lib installed use line ruby system visual folder import debug php program process\n",
      "Topic #6:\n",
      "c int class std function x foo type b return variable value const operator code char use object string public pointer f method compiler argument double void like bar error vector struct parameter member include template would using constructor static\n",
      "Topic #7:\n",
      "string array list value object python key number way convert like character item x c return want get function var b would name new print int n dictionary element java loop integer using line method map use one example data\n",
      "Topic #8:\n",
      "git branch commit repository file master repo remote github push merge change pull origin directory local command folder head want project delete status way one feature tag fatal team ref like add fetch reset get working back new using would\n",
      "Topic #9:\n",
      "table div column row sql id cs query mysql px select width cell li height text image database style class like font color value data html element name panda want using span df background border insert dataframe left top index\n",
      "Topic #10:\n",
      "request user url data model json http error get name post response server string id new using file php function return password email public com controller app session net set client code var react connection log api rail username page\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 40\n",
    "print(\"\\nTopics in LDA model: \")\n",
    "print_top_words(lda, feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On extrait le 1er tag de chaque ligne pour créer 'y' de la base train et test. Il faut encoder les données sur le dataframe contenant toutes les données pour éviter des problèmes liés avec des tags qui apparaissent dans une base et non l'autre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = pd.concat([train_df, test_df])\n",
    "pre_base = [full_df['processed_tags'].iloc[i][0]\n",
    "            for i in range(len(full_df['processed_tags']))]\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(pre_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_ytrain = [train_df['processed_tags'].iloc[i][0]\n",
    "              for i in range(len(train_df['processed_tags']))]\n",
    "y_train = le.transform(pre_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_ytest = [test_df['processed_tags'].iloc[i][0]\n",
    "             for i in range(len(test_df['processed_tags']))]\n",
    "y_test = le.transform(pre_ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation de la base train\n",
    "std_scale = preprocessing.StandardScaler().fit(train_mx)\n",
    "X_scaled = std_scale.transform(train_mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation de la base test selon la base test\n",
    "X_scaled_test = std_scale.transform(test_mx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On test l'ACP avec plusieurs nombres de composants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On calcul les 2 premieres composantes principales\n",
    "pca = decomposition.PCA(n_components=800)\n",
    "pca.fit(X_scaled)\n",
    "\n",
    "# projeter X sur les composantes principales\n",
    "train_projected = pca.transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_projected = pca.transform(X_scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8925587586009399\n"
     ]
    }
   ],
   "source": [
    "# Pourcentage de la variance expliquee\n",
    "# print(pca.explained_variance_ratio_)\n",
    "print(pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "scree = pca.explained_variance_ratio_*100\n",
    "#plt.bar(np.arange(len(scree))+1, scree)\n",
    "plt.plot(np.arange(len(scree)), np.cumsum(pca.explained_variance_ratio_), 'r-')\n",
    "plt.xlabel('Nombre de composantes principales')\n",
    "plt.ylabel('Pourcentage de la variance expliquee')\n",
    "plt.title(\"Eboulis des valeurs propres\")\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On enregistre les composantes dans une variable qui devient le nouveau x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34876, 800)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_projected.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V1 - Modélisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons tester trois modèles différents pour trouver celui ayant la meilleure précision. Les trois modèles choisis sont:\n",
    "- l'arbre de décision\n",
    "- le modèle logisitique\n",
    "- la SVM\n",
    "\n",
    "Cette première version est simplement un premier jet, les versions suivantes sont plus travaillées et utiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbre de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34876, 977)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34876,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:672: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([102.06740141, 102.67597294, 109.02975059, 104.48239422,\n",
       "        103.40116   ]),\n",
       " 'score_time': array([0.03195596, 0.02400041, 0.02400041, 0.02453303, 0.02403855]),\n",
       " 'test_score': array([0.38704128, 0.38308244, 0.37749104, 0.39268817, 0.38566308]),\n",
       " 'train_score': array([0.99989247, 0.99992832, 0.99992832, 0.99992832, 0.99992832])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_class = DecisionTreeClassifier()\n",
    "scores = cross_validate(estimator=tree_class, X=train_projected, y=y_train, cv=5, scoring=(\n",
    "    'accuracy'), return_train_score=True)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Accuracy moyenne pour data train:', scores['train_accuracy'].mean())\n",
    "\n",
    "#print('Accuracy moyen pour data test:', scores['test_accuracy'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy avec modèle: Arbre de décision: 0.39358736059479554\n",
      "144.60286808013916\n"
     ]
    }
   ],
   "source": [
    "debut = time.time()\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(train_projected, y_train)\n",
    "fin = time.time()\n",
    "print('Accuracy avec modèle: Arbre de décision:',\n",
    "      decision_tree.score(test_projected, y_test))\n",
    "print(fin-debut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "parameters = {'penalty': ['none'], 'C': [\n",
    "    0.01, 1, 100], 'max_iter': [1000]}\n",
    "gs_reglog = GridSearchCV(model, parameters, scoring=(\n",
    "    'accuracy'), refit='r2', cv=5)\n",
    "gs_reglog.fit(train_projected, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modele_logit = LogisticRegression(penalty='none')\n",
    "modele_logit.fit(train_projected, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(X_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V2 - Modélisation sur un échantillon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour tester le bon fonctionnement des modèles, nous avons sélectionné les 10 000 première valeurs de X et Y afin de pouvoir faire tourner les algorithmes plus facilement. Cependant le résultat de ces tests là ne sont pas pris en compte dans le choix du modèle final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_projected[:10000]\n",
    "y = y_train[:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbre de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_class = DecisionTreeClassifier()\n",
    "tree_class.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35931691449814124\n",
      "0.08591997447324211\n",
      "0.08637855735368614\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.03      0.03       106\n",
      "           3       0.00      0.00      0.00         3\n",
      "           5       0.47      0.46      0.46       800\n",
      "          10       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         6\n",
      "          14       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         1\n",
      "          23       0.14      0.15      0.15       197\n",
      "          24       0.30      0.26      0.28      1033\n",
      "          26       0.46      0.46      0.46       621\n",
      "          27       0.00      0.00      0.00         0\n",
      "          32       0.00      0.00      0.00         0\n",
      "          33       0.30      0.24      0.27       173\n",
      "          35       0.00      0.00      0.00         1\n",
      "          36       0.00      0.00      0.00         4\n",
      "          37       0.00      0.00      0.00         1\n",
      "          38       0.00      0.00      0.00         7\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         2\n",
      "          46       0.00      0.00      0.00         1\n",
      "          48       0.00      0.00      0.00         1\n",
      "          49       0.72      0.77      0.75       258\n",
      "          51       0.00      0.00      0.00         0\n",
      "          55       0.27      0.31      0.29       260\n",
      "          56       0.00      0.00      0.00         1\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00         1\n",
      "          60       0.00      0.00      0.00         1\n",
      "          61       0.00      0.00      0.00         0\n",
      "          63       0.29      0.29      0.29       360\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.05      0.04      0.05       185\n",
      "          68       0.00      0.00      0.00         1\n",
      "          70       0.42      0.44      0.43      1082\n",
      "          71       0.39      0.41      0.40      1077\n",
      "          72       0.00      0.00      0.00         1\n",
      "          73       0.12      0.12      0.12       179\n",
      "          75       0.00      0.00      0.00         1\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       0.00      0.00      0.00         2\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         3\n",
      "          81       0.31      0.30      0.31       167\n",
      "          82       0.00      0.00      0.00         0\n",
      "          84       0.08      0.09      0.08        93\n",
      "          87       0.15      0.14      0.14       436\n",
      "          90       0.51      0.51      0.51      1026\n",
      "          91       0.00      0.00      0.00         1\n",
      "          92       0.14      0.18      0.16       104\n",
      "          93       0.20      0.17      0.19       203\n",
      "          94       0.00      0.00      0.00         0\n",
      "          97       0.00      0.00      0.00         0\n",
      "          99       0.32      0.33      0.32       190\n",
      "         102       0.00      0.00      0.00         4\n",
      "         104       0.00      0.00      0.00         0\n",
      "         106       0.00      0.00      0.00         1\n",
      "         110       0.00      0.00      0.00         1\n",
      "         113       0.00      0.00      0.00         0\n",
      "         115       0.00      0.00      0.00         1\n",
      "         116       0.00      0.00      0.00         0\n",
      "         118       0.00      0.00      0.00         1\n",
      "         120       0.00      0.00      0.00         6\n",
      "         122       0.00      0.00      0.00         1\n",
      "         123       0.00      0.00      0.00         0\n",
      "         124       0.00      0.00      0.00         0\n",
      "         125       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.36      8608\n",
      "   macro avg       0.09      0.09      0.09      8608\n",
      "weighted avg       0.36      0.36      0.36      8608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = tree_class.predict(test_projected[:10000])\n",
    "\n",
    "print(f1_score(y_test[:10000], y_pred, average='micro'))\n",
    "print(precision_score(y_test[:10000], y_pred, average=\"macro\"))\n",
    "print(recall_score(y_test[:10000], y_pred, average=\"macro\"))\n",
    "print(classification_report(y_test[:10000], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6011849442379182\n",
      "0.18664315696661823\n",
      "0.18687764274111676\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.17      0.15       106\n",
      "           3       0.00      0.00      0.00         3\n",
      "           5       0.63      0.64      0.64       800\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         6\n",
      "          16       0.00      0.00      0.00         1\n",
      "          23       0.38      0.40      0.39       197\n",
      "          24       0.62      0.57      0.59      1033\n",
      "          26       0.61      0.62      0.61       621\n",
      "          33       0.41      0.29      0.34       173\n",
      "          35       0.00      0.00      0.00         1\n",
      "          36       0.00      0.00      0.00         4\n",
      "          37       0.00      0.00      0.00         1\n",
      "          38       0.00      0.00      0.00         7\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         2\n",
      "          44       0.00      0.00      0.00         0\n",
      "          46       0.00      0.00      0.00         1\n",
      "          48       0.00      0.00      0.00         1\n",
      "          49       0.90      0.84      0.87       258\n",
      "          55       0.35      0.44      0.39       260\n",
      "          56       0.00      0.00      0.00         1\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00         1\n",
      "          60       0.00      0.00      0.00         1\n",
      "          61       0.00      0.00      0.00         0\n",
      "          63       0.56      0.56      0.56       360\n",
      "          66       0.24      0.20      0.22       185\n",
      "          68       0.00      0.00      0.00         1\n",
      "          70       0.62      0.64      0.63      1082\n",
      "          71       0.64      0.69      0.67      1077\n",
      "          72       0.00      0.00      0.00         1\n",
      "          73       0.35      0.36      0.35       179\n",
      "          75       0.00      0.00      0.00         1\n",
      "          78       0.00      0.00      0.00         2\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         3\n",
      "          81       0.58      0.57      0.58       167\n",
      "          84       0.16      0.16      0.16        93\n",
      "          87       0.67      0.63      0.65       436\n",
      "          90       0.80      0.81      0.80      1026\n",
      "          91       0.00      0.00      0.00         1\n",
      "          92       0.45      0.51      0.48       104\n",
      "          93       0.62      0.52      0.57       203\n",
      "          94       0.00      0.00      0.00         0\n",
      "          99       0.54      0.52      0.53       190\n",
      "         102       0.00      0.00      0.00         4\n",
      "         106       0.00      0.00      0.00         1\n",
      "         110       0.00      0.00      0.00         1\n",
      "         115       0.00      0.00      0.00         1\n",
      "         118       0.00      0.00      0.00         1\n",
      "         120       0.18      0.33      0.24         6\n",
      "         122       0.00      0.00      0.00         1\n",
      "         125       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.60      8608\n",
      "   macro avg       0.19      0.19      0.19      8608\n",
      "weighted avg       0.60      0.60      0.60      8608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = log_reg.predict(test_projected[:10000])\n",
    "\n",
    "print(f1_score(y_test[:10000], y_pred, average='micro'))\n",
    "print(precision_score(y_test[:10000], y_pred, average=\"macro\"))\n",
    "print(recall_score(y_test[:10000], y_pred, average=\"macro\"))\n",
    "print(classification_report(y_test[:10000], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6442843866171004\n",
      "0.27631817799096065\n",
      "0.19266478030209178\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.02       106\n",
      "           3       0.00      0.00      0.00         3\n",
      "           5       0.71      0.76      0.73       800\n",
      "          13       0.00      0.00      0.00         6\n",
      "          16       0.00      0.00      0.00         1\n",
      "          23       0.69      0.17      0.28       197\n",
      "          24       0.55      0.71      0.62      1033\n",
      "          26       0.71      0.66      0.68       621\n",
      "          33       0.46      0.14      0.21       173\n",
      "          35       0.00      0.00      0.00         1\n",
      "          36       0.00      0.00      0.00         4\n",
      "          37       0.00      0.00      0.00         1\n",
      "          38       0.00      0.00      0.00         7\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         2\n",
      "          46       0.00      0.00      0.00         1\n",
      "          48       0.00      0.00      0.00         1\n",
      "          49       0.91      0.89      0.90       258\n",
      "          55       0.43      0.50      0.46       260\n",
      "          56       0.00      0.00      0.00         1\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00         1\n",
      "          60       0.00      0.00      0.00         1\n",
      "          63       0.65      0.63      0.64       360\n",
      "          66       0.64      0.10      0.17       185\n",
      "          68       0.00      0.00      0.00         1\n",
      "          70       0.55      0.75      0.64      1082\n",
      "          71       0.62      0.80      0.70      1077\n",
      "          72       0.00      0.00      0.00         1\n",
      "          73       0.52      0.08      0.14       179\n",
      "          75       0.00      0.00      0.00         1\n",
      "          78       0.00      0.00      0.00         2\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         3\n",
      "          81       0.64      0.62      0.63       167\n",
      "          84       1.00      0.02      0.04        93\n",
      "          87       0.81      0.50      0.62       436\n",
      "          90       0.77      0.86      0.81      1026\n",
      "          91       0.00      0.00      0.00         1\n",
      "          92       0.67      0.46      0.55       104\n",
      "          93       0.84      0.42      0.56       203\n",
      "          99       0.65      0.56      0.60       190\n",
      "         102       0.00      0.00      0.00         4\n",
      "         106       0.00      0.00      0.00         1\n",
      "         110       0.00      0.00      0.00         1\n",
      "         115       0.00      0.00      0.00         1\n",
      "         118       0.00      0.00      0.00         1\n",
      "         120       0.00      0.00      0.00         6\n",
      "         122       0.00      0.00      0.00         1\n",
      "         125       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.64      8608\n",
      "   macro avg       0.28      0.19      0.20      8608\n",
      "weighted avg       0.66      0.64      0.62      8608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = svm.predict(test_projected[:10000])\n",
    "\n",
    "print(f1_score(y_test[:10000], y_pred, average='micro'))\n",
    "print(precision_score(y_test[:10000], y_pred, average=\"macro\"))\n",
    "print(recall_score(y_test[:10000], y_pred, average=\"macro\"))\n",
    "print(classification_report(y_test[:10000], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modélisation sur toutes les données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests sur google colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le jeu de données étant très important, j'ai rencontré des difficultées à faire tourner ces codes sur jupyter. J'ai donc fait certains tests sur google colab en utilisant le GPU. Pour pouvoir faire cela, il m'a fallu transférer les données sur google colab et vérifier leur forme et leur taille."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_projected\n",
    "y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34876, 800)\n",
      "(34876,)\n",
      "(8608, 800)\n",
      "(8608,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(test_projected.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [[-1.54483905e+00  1.40083500e+00  2.09303001e-01 ...  5.95326544e-01\n",
      "  -1.49504499e+00  1.88269706e-03]\n",
      " [ 1.94528506e+00  3.70442646e+00  1.60432818e+00 ... -8.55249506e-01\n",
      "   4.42822787e-01 -4.55148339e-01]\n",
      " [-1.50849740e+00  1.05434131e+00 -1.39288707e+00 ... -8.27174283e-01\n",
      "   1.54222195e-01 -3.92614353e-01]\n",
      " ...\n",
      " [-1.16020402e+00 -1.43050418e+00  1.24224145e+00 ... -9.59776741e-01\n",
      "   3.68352733e-01  6.73205581e-01]\n",
      " [-1.95723822e+00  2.50974079e+00 -4.69779461e-01 ... -1.24035355e+00\n",
      "  -3.38761822e-01  1.00341782e+00]\n",
      " [-1.00379294e+00  8.07275756e+00  3.20417663e+00 ...  3.32758555e-01\n",
      "   3.38913789e-01  7.86003475e-01]]\n",
      "y: [70  5 49 ... 90 24 70]\n",
      "test_projected: [[-4.06875168e-01 -1.53030168e+00  1.17995040e+00 ... -3.62408619e-01\n",
      "  -1.21246430e+00  3.33093006e-01]\n",
      " [ 5.87253361e+00 -9.78786830e-01 -3.54447288e+00 ...  6.80748976e-01\n",
      "  -9.76319228e-01 -2.99488660e-01]\n",
      " [ 3.33907724e+00 -9.74049512e-01  6.65564624e-01 ... -1.30880693e+00\n",
      "  -1.40185833e+00  7.36984024e-03]\n",
      " ...\n",
      " [-4.70425274e-03 -2.27856009e+00 -2.73197115e-01 ...  7.57502910e-01\n",
      "   1.36220525e+00 -3.48663175e-01]\n",
      " [-5.25832756e-01 -1.54591251e+00 -4.55693979e-01 ...  1.47172641e+00\n",
      "   4.95587041e-01  1.24978466e+00]\n",
      " [ 3.38705222e+00 -2.42664397e+00 -1.28079057e+00 ... -7.76922824e-01\n",
      "   1.04976031e+00 -1.52313709e-01]]\n",
      "y_test: [90 55  5 ... 87 70 24]\n"
     ]
    }
   ],
   "source": [
    "print('X:', X)\n",
    "print('y:', y)\n",
    "print('test_projected:', test_projected)\n",
    "print('y_test:', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde des données pour utiliser dans google colab\n",
    "np.savetxt('X.csv', X, delimiter=',', fmt='%d', header='Values')\n",
    "np.savetxt('Y.csv', y, delimiter=',', fmt='%d', header='Values')\n",
    "np.savetxt('test_proj.csv', test_projected,\n",
    "           delimiter=',', fmt='%d', header='Values')\n",
    "np.savetxt('y_test.csv', y_test, delimiter=',', fmt='%d', header='Values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choix du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arbre de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3888243494423792\n",
      "0.09122714429293237\n",
      "0.09171257460604516\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.08      0.08       106\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.51      0.51      0.51       800\n",
      "           9       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         6\n",
      "          16       0.00      0.00      0.00         1\n",
      "          23       0.24      0.23      0.24       197\n",
      "          24       0.35      0.34      0.35      1033\n",
      "          26       0.49      0.46      0.48       621\n",
      "          33       0.23      0.24      0.23       173\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         1\n",
      "          36       0.00      0.00      0.00         4\n",
      "          37       0.00      0.00      0.00         1\n",
      "          38       0.00      0.00      0.00         7\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         2\n",
      "          46       0.00      0.00      0.00         1\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       0.00      0.00      0.00         1\n",
      "          49       0.75      0.76      0.76       258\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.00      0.00      0.00         0\n",
      "          55       0.21      0.20      0.21       260\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.00      0.00      0.00         0\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00         1\n",
      "          60       0.00      0.00      0.00         1\n",
      "          63       0.30      0.34      0.32       360\n",
      "          64       0.00      0.00      0.00         0\n",
      "          66       0.13      0.10      0.11       185\n",
      "          68       0.00      0.00      0.00         1\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.42      0.43      0.43      1082\n",
      "          71       0.46      0.44      0.45      1077\n",
      "          72       0.00      0.00      0.00         1\n",
      "          73       0.16      0.17      0.17       179\n",
      "          75       0.00      0.00      0.00         1\n",
      "          76       0.00      0.00      0.00         0\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       0.00      0.00      0.00         2\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         3\n",
      "          81       0.29      0.30      0.30       167\n",
      "          82       0.00      0.00      0.00         0\n",
      "          84       0.05      0.04      0.05        93\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.21      0.20      0.20       436\n",
      "          90       0.56      0.55      0.56      1026\n",
      "          91       0.00      0.00      0.00         1\n",
      "          92       0.15      0.21      0.17       104\n",
      "          93       0.22      0.19      0.20       203\n",
      "          94       0.00      0.00      0.00         0\n",
      "          99       0.32      0.32      0.32       190\n",
      "         102       0.00      0.00      0.00         4\n",
      "         106       0.00      0.00      0.00         1\n",
      "         110       0.00      0.00      0.00         1\n",
      "         114       0.00      0.00      0.00         0\n",
      "         115       0.00      0.00      0.00         1\n",
      "         118       0.00      0.00      0.00         1\n",
      "         120       0.00      0.00      0.00         6\n",
      "         122       0.00      0.00      0.00         1\n",
      "         124       0.00      0.00      0.00         0\n",
      "         125       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.39      8608\n",
      "   macro avg       0.09      0.09      0.09      8608\n",
      "weighted avg       0.39      0.39      0.39      8608\n",
      "\n",
      "Temps d'exécution:  142.0283327102661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "debut_tree = time.time()\n",
    "\n",
    "tree_class = DecisionTreeClassifier()\n",
    "tree_class.fit(X, y)\n",
    "\n",
    "y_pred = tree_class.predict(test_projected)\n",
    "\n",
    "fin_tree =  time.time()\n",
    "print(f1_score(y_test, y_pred, average='micro'))\n",
    "print(precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(recall_score(y_test, y_pred, average=\"macro\"))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Temps d'exécution: \", fin_tree - debut_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6780901486988847\n",
      "0.22654798314536978\n",
      "0.21207425189923196\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.16      0.18       106\n",
      "           1       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         3\n",
      "           5       0.81      0.78      0.79       800\n",
      "          13       0.00      0.00      0.00         6\n",
      "          14       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         1\n",
      "          23       0.49      0.48      0.48       197\n",
      "          24       0.67      0.67      0.67      1033\n",
      "          26       0.71      0.68      0.70       621\n",
      "          33       0.51      0.45      0.48       173\n",
      "          35       0.00      0.00      0.00         1\n",
      "          36       0.00      0.00      0.00         4\n",
      "          37       0.00      0.00      0.00         1\n",
      "          38       1.00      0.14      0.25         7\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         2\n",
      "          44       0.00      0.00      0.00         0\n",
      "          46       0.00      0.00      0.00         1\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       0.00      0.00      0.00         1\n",
      "          49       0.85      0.87      0.86       258\n",
      "          55       0.45      0.49      0.47       260\n",
      "          56       0.00      0.00      0.00         1\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00         1\n",
      "          60       0.00      0.00      0.00         1\n",
      "          63       0.58      0.64      0.61       360\n",
      "          66       0.33      0.28      0.30       185\n",
      "          68       0.00      0.00      0.00         1\n",
      "          70       0.73      0.74      0.73      1082\n",
      "          71       0.73      0.75      0.74      1077\n",
      "          72       0.00      0.00      0.00         1\n",
      "          73       0.41      0.38      0.39       179\n",
      "          75       0.00      0.00      0.00         1\n",
      "          78       0.00      0.00      0.00         2\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         3\n",
      "          81       0.60      0.62      0.61       167\n",
      "          84       0.13      0.13      0.13        93\n",
      "          87       0.70      0.70      0.70       436\n",
      "          90       0.85      0.87      0.86      1026\n",
      "          91       0.00      0.00      0.00         1\n",
      "          92       0.43      0.50      0.46       104\n",
      "          93       0.63      0.62      0.62       203\n",
      "          99       0.58      0.55      0.56       190\n",
      "         102       0.00      0.00      0.00         4\n",
      "         106       0.00      0.00      0.00         1\n",
      "         110       0.00      0.00      0.00         1\n",
      "         115       0.00      0.00      0.00         1\n",
      "         118       0.00      0.00      0.00         1\n",
      "         120       0.08      0.17      0.11         6\n",
      "         122       0.00      0.00      0.00         1\n",
      "         124       0.00      0.00      0.00         0\n",
      "         125       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.68      8608\n",
      "   macro avg       0.23      0.21      0.21      8608\n",
      "weighted avg       0.68      0.68      0.68      8608\n",
      "\n",
      "Temps d'exécution:  29.531790018081665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "debut_reg = time.time()\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X, y)\n",
    "y_pred = log_reg.predict(test_projected)\n",
    "\n",
    "fin_reg = time.time()\n",
    "print(f1_score(y_test, y_pred, average='micro'))\n",
    "print(precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(recall_score(y_test, y_pred, average=\"macro\"))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Temps d'exécution: \", fin_reg - debut_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "debut_svm = time.time()\n",
    "\n",
    "svm = SVC()\n",
    "svm.fit(X, y)\n",
    "y_pred = svm.predict(test_projected)\n",
    "\n",
    "fin_svm = time.time()\n",
    "print(f1_score(y_test, y_pred, average='micro'))\n",
    "print(precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(recall_score(y_test, y_pred, average=\"macro\"))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Temps d'éxecution: \", fin_svm - debut_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle choisi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le meilleur score est atteint avec la SVM (accuracy = 0,69). Cependant, du au temps d'exécution trop long, le modèle choisi est la régression logistique avec un score accuracy de 0,68 avec les paramètres par défaut suivants: {'C': 1, 'max_iter': 100, 'penalty': 'l2'}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning des paramètres : GridSearchCV V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'penalty': ['l1', 'none'],\n",
    "    'C': [1, 10, 100],\n",
    "    'max_iter': [100, 500]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:672: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 16.0min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 132.8min finished\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid,\n",
    "                           cv=5, scoring=\"accuracy\", verbose=2, n_jobs=-1)\n",
    "\n",
    "best_model = grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'max_iter': 100, 'penalty': 'none'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7078984122716542"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning des paramètres : GridSearchCV V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:672: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed: 117.1min finished\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [1, 10],\n",
    "    'max_iter': [100, 1000]\n",
    "}\n",
    "model = LogisticRegression()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid,\n",
    "                           cv=5, scoring=\"accuracy\", verbose=2, n_jobs=-1)\n",
    "best_model = grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'max_iter': 1000, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7104861373516822"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning des paramètres : GridSearchCV V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'penalty': ['l2', 'none'],\n",
    "     'C': np.logspace(-2,2,5),\n",
    "    'max_iter': [50,100]\n",
    "}\n",
    "model = LogisticRegression()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring=\"accuracy\", verbose=2, n_jobs=-1)\n",
    "best_model = grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meilleurs paramètres: {'C': 0.01, 'max_iter': 50, 'penalty': 'l2'}\n",
    "\n",
    "Meilleur score: 0.670891194797935"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning des paramètres : GridSearchCV V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'penalty': ['l2', 'none'],\n",
    "     'C': np.logspace(-1,2,4),\n",
    "    'max_iter': [100,1000]\n",
    "}\n",
    "model = LogisticRegression()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring=\"accuracy\", verbose=2, n_jobs=-1)\n",
    "best_model = grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meilleurs paramètres: {'C': 0.1, 'max_iter': 1000, 'penalty': 'l2'}\n",
    "Meilleur score: 0.6458596765972839"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paramètres choisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir testé différents paramètres, le meilleur score reste celui obtenu avec les paramètres par défaut du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_projected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.16      0.18       106\n",
      "           1       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         3\n",
      "           5       0.81      0.78      0.79       800\n",
      "          13       0.00      0.00      0.00         6\n",
      "          14       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         1\n",
      "          23       0.49      0.48      0.48       197\n",
      "          24       0.67      0.67      0.67      1033\n",
      "          26       0.71      0.68      0.70       621\n",
      "          33       0.51      0.45      0.48       173\n",
      "          35       0.00      0.00      0.00         1\n",
      "          36       0.00      0.00      0.00         4\n",
      "          37       0.00      0.00      0.00         1\n",
      "          38       1.00      0.14      0.25         7\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         2\n",
      "          44       0.00      0.00      0.00         0\n",
      "          46       0.00      0.00      0.00         1\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       0.00      0.00      0.00         1\n",
      "          49       0.85      0.87      0.86       258\n",
      "          55       0.45      0.49      0.47       260\n",
      "          56       0.00      0.00      0.00         1\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00         1\n",
      "          60       0.00      0.00      0.00         1\n",
      "          63       0.58      0.64      0.61       360\n",
      "          66       0.33      0.28      0.30       185\n",
      "          68       0.00      0.00      0.00         1\n",
      "          70       0.73      0.74      0.73      1082\n",
      "          71       0.73      0.75      0.74      1077\n",
      "          72       0.00      0.00      0.00         1\n",
      "          73       0.41      0.38      0.39       179\n",
      "          75       0.00      0.00      0.00         1\n",
      "          78       0.00      0.00      0.00         2\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         3\n",
      "          81       0.60      0.62      0.61       167\n",
      "          84       0.13      0.13      0.13        93\n",
      "          87       0.70      0.70      0.70       436\n",
      "          90       0.85      0.87      0.86      1026\n",
      "          91       0.00      0.00      0.00         1\n",
      "          92       0.43      0.50      0.46       104\n",
      "          93       0.63      0.62      0.62       203\n",
      "          99       0.58      0.55      0.56       190\n",
      "         102       0.00      0.00      0.00         4\n",
      "         106       0.00      0.00      0.00         1\n",
      "         110       0.00      0.00      0.00         1\n",
      "         115       0.00      0.00      0.00         1\n",
      "         118       0.00      0.00      0.00         1\n",
      "         120       0.08      0.17      0.11         6\n",
      "         122       0.00      0.00      0.00         1\n",
      "         124       0.00      0.00      0.00         0\n",
      "         125       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.68      8608\n",
      "   macro avg       0.23      0.21      0.21      8608\n",
      "weighted avg       0.68      0.68      0.68      8608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Happy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_final = LogisticRegression()\n",
    "model_final.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model_final.predict(test_projected)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_final.plk']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model_final, 'model_final.plk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
